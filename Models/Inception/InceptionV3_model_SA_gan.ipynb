{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFXvgzy18_Zx","executionInfo":{"status":"ok","timestamp":1667801247232,"user_tz":-480,"elapsed":25860,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}},"outputId":"852aac73-1ab8-4d28-c01f-07097d9f3745"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip -d ./dataverse_files /content/drive/MyDrive/dataverse_files.zip\n","\n","!unzip -d ./dataverse_files/HAM10000_images_part_1 /content/dataverse_files/HAM10000_images_part_1.zip\n","!unzip -d ./dataverse_files/HAM10000_images_part_2 /content/dataverse_files/HAM10000_images_part_2.zip\n","!unzip -d ./dataverse_files /content/dataverse_files/ISIC2018_Task3_Test_Images.zip\n","\n","!unzip -d ./dataverse_files /content/drive/MyDrive/InceptionV3.zip\n","\n","!unzip -d ./dataverse_files /content/dataverse_files/GAN_Images-20221105T161540Z-001.zip\n","!unzip -d ./dataverse_files /content/dataverse_files/HAM10000_images_augmented-20221103T160519Z-001.zip"],"metadata":{"id":"hkMRUU1Y-uRY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXsRqaAw8uSC"},"source":["# 1. Preprocessing"]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import shutil"],"metadata":{"id":"-9GMygDv9MXz","executionInfo":{"status":"ok","timestamp":1667801335913,"user_tz":-480,"elapsed":622,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"c7Pq1JKY8uSE","executionInfo":{"status":"ok","timestamp":1667801338555,"user_tz":-480,"elapsed":2661,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[],"source":["# move training images into folders\n","\n","# create train folder\n","if not os.path.exists('dataverse_files/train'):\n","    os.mkdir('dataverse_files/train')\n","    \n","for img_name in os.listdir('dataverse_files/HAM10000_images_part_1/'):\n","    src_path = os.path.join('dataverse_files/HAM10000_images_part_1', img_name)\n","    tgt_path = 'dataverse_files/train'\n","    shutil.move(src_path, tgt_path)\n","    \n","for img_name in os.listdir('dataverse_files/HAM10000_images_part_2/'):\n","    src_path = os.path.join('dataverse_files/HAM10000_images_part_2', img_name)\n","    tgt_path = 'dataverse_files/train'\n","    shutil.move(src_path, tgt_path)\n","\n","for img_name in os.listdir('dataverse_files/HAM10000_images_augmented/'):\n","    src_path = os.path.join('dataverse_files/HAM10000_images_augmented', img_name)\n","    renamed_src_path = os.path.join('dataverse_files/HAM10000_images_augmented', img_name.split('.')[0] + '_aug.jpg')\n","    os.rename(src_path, renamed_src_path)\n","    tgt_path = 'dataverse_files/train'\n","    shutil.move(renamed_src_path, tgt_path)\n","\n","for img_name in os.listdir('dataverse_files/GAN_Images/'):\n","    src_path = os.path.join('dataverse_files/GAN_Images', img_name)\n","    tgt_path = 'dataverse_files/train'\n","    shutil.move(src_path, tgt_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"AanXRTN48uSF","executionInfo":{"status":"ok","timestamp":1667801339449,"user_tz":-480,"elapsed":902,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","train_df = pd.read_csv('dataverse_files/HAM10000_metadata')\n","aug_train_df = pd.read_csv('dataverse_files/HAM10000_metadata_augmented.csv').iloc[:, 1:]\n","aug_train_df['image_id'] = aug_train_df['image_id'].apply(lambda x: x+'_aug')\n","\n","gan_df = pd.read_csv('dataverse_files/HAM10000_GAN_data.csv').iloc[:, 1:]\n","\n","train, test = train_test_split(train_df[['image_id', 'dx']], test_size=0.2)\n","train = pd.concat((train, aug_train_df[['image_id', 'dx']]), axis=0)\n","\n","gan_df['dx'] = gan_df['dx'].map({0: 'bkl', 1: 'nv', 2: 'df', 3: 'mel', 4: 'vasc', 5: 'bcc', 6: 'akiec'})\n","train = pd.concat((train, gan_df[['image_id', 'dx']]), axis=0)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WvoQ-GyK8uSF","executionInfo":{"status":"ok","timestamp":1667801339450,"user_tz":-480,"elapsed":8,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[],"source":["# convert to numerical representation\n","from sklearn.preprocessing import LabelEncoder\n","\n","lb = LabelEncoder()\n","lb.fit_transform(train_df['dx'])\n","cls2lbl = {cls: idx for idx, cls in enumerate(lb.classes_)}\n","lbl2cls = {idx: cls for idx, cls in enumerate(lb.classes_)}\n","train['label'] = [cls2lbl[cls] for cls in train['dx']]\n","test['label'] = [cls2lbl[cls] for cls in test['dx']]"]},{"cell_type":"markdown","metadata":{"id":"k84fTnEQ8uSH"},"source":["# 2. Data loader"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"rtcplVLc8uSI","executionInfo":{"status":"ok","timestamp":1667801340617,"user_tz":-480,"elapsed":1173,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[],"source":["from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import ToTensor, RandomAffine, Resize, CenterCrop, Normalize\n","\n","class MyDataset(Dataset):\n","    def __init__(self, mode='train'):\n","        self.meta = train if mode == 'train' else test\n","        self.root_dir = 'dataverse_files/train'\n","    def __len__(self):\n","        return len(self.meta)\n","    def __getitem__(self, idx):\n","        if self.meta['image_id'].iloc[idx].startswith('GAN'):\n","            img_name = self.meta['image_id'].iloc[idx]\n","        else:\n","            img_name = self.meta['image_id'].iloc[idx] + '.jpg'\n","        img_path = os.path.join(self.root_dir, img_name)\n","\n","        image = Image.open(img_path)\n","        image = Resize((299, 299))(image)\n","        image = RandomAffine(degrees=(-10, 10), translate=(0.05, 0.1), scale=(0.9, 1.1))(image)\n","        image = ToTensor()(image)\n","        image = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n","        \n","        label = self.meta['label'].iloc[idx]\n","        return image, label\n","\n","train_dataset = MyDataset(mode='train')\n","test_dataset = MyDataset(mode='test')\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"26caNCCK8uSJ"},"source":["# 3. Models"]},{"cell_type":"code","execution_count":8,"metadata":{"scrolled":true,"id":"rkc2RY-v8uSJ","outputId":"e0e4ceb1-a754-497f-a201-4847c1782587","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667801341703,"user_tz":-480,"elapsed":1090,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["Inception3(\n","  (Conv2d_1a_3x3): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2a_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2b_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Conv2d_3b_1x1): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_4a_3x3): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Mixed_5b): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5c): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5d): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6a): InceptionB(\n","    (branch3x3): BasicConv2d(\n","      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6b): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6c): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6d): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6e): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (AuxLogits): InceptionAux(\n","    (conv0): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv1): BasicConv2d(\n","      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (fc): Linear(in_features=768, out_features=1000, bias=True)\n","  )\n","  (Mixed_7a): InceptionD(\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7b): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7c): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=7, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":8}],"source":["import torch.nn as nn\n","from torchvision.models import inception_v3\n","\n","model = inception_v3(pretrained=False)\n","# for param in model.parameters():\n","#     param.requires_grad = False\n","\n","model.fc = nn.Sequential(nn.Linear(2048, 7))\n","model"]},{"cell_type":"markdown","metadata":{"id":"gk7cVHwN8uSK"},"source":["# 4. Train"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"VJTD29ST8uSK","outputId":"4cb9b068-a42f-4f65-d51a-cfa5ca95a655","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667811334889,"user_tz":-480,"elapsed":9993190,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 1/20, Step: 10/626, Loss: 1.7914\n","Iteration: 1/20, Step: 20/626, Loss: 1.6374\n","Iteration: 1/20, Step: 30/626, Loss: 1.8937\n","Iteration: 1/20, Step: 40/626, Loss: 1.8322\n","Iteration: 1/20, Step: 50/626, Loss: 1.3429\n","Iteration: 1/20, Step: 60/626, Loss: 1.3094\n","Iteration: 1/20, Step: 70/626, Loss: 1.3158\n","Iteration: 1/20, Step: 80/626, Loss: 1.5786\n","Iteration: 1/20, Step: 90/626, Loss: 1.3258\n","Iteration: 1/20, Step: 100/626, Loss: 1.7248\n","Iteration: 1/20, Step: 110/626, Loss: 1.1976\n","Iteration: 1/20, Step: 120/626, Loss: 1.4209\n","Iteration: 1/20, Step: 130/626, Loss: 1.3014\n","Iteration: 1/20, Step: 140/626, Loss: 1.3774\n","Iteration: 1/20, Step: 150/626, Loss: 1.3405\n","Iteration: 1/20, Step: 160/626, Loss: 1.8154\n","Iteration: 1/20, Step: 170/626, Loss: 1.6056\n","Iteration: 1/20, Step: 180/626, Loss: 1.4325\n","Iteration: 1/20, Step: 190/626, Loss: 1.7648\n","Iteration: 1/20, Step: 200/626, Loss: 1.2472\n","Iteration: 1/20, Step: 210/626, Loss: 1.4391\n","Iteration: 1/20, Step: 220/626, Loss: 1.4815\n","Iteration: 1/20, Step: 230/626, Loss: 1.3084\n","Iteration: 1/20, Step: 240/626, Loss: 1.4684\n","Iteration: 1/20, Step: 250/626, Loss: 1.2996\n","Iteration: 1/20, Step: 260/626, Loss: 1.2506\n","Iteration: 1/20, Step: 270/626, Loss: 1.6319\n","Iteration: 1/20, Step: 280/626, Loss: 1.3233\n","Iteration: 1/20, Step: 290/626, Loss: 1.4106\n","Iteration: 1/20, Step: 300/626, Loss: 1.3187\n","Iteration: 1/20, Step: 310/626, Loss: 1.3500\n","Iteration: 1/20, Step: 320/626, Loss: 1.1514\n","Iteration: 1/20, Step: 330/626, Loss: 1.3384\n","Iteration: 1/20, Step: 340/626, Loss: 1.3324\n","Iteration: 1/20, Step: 350/626, Loss: 1.2568\n","Iteration: 1/20, Step: 360/626, Loss: 1.3514\n","Iteration: 1/20, Step: 370/626, Loss: 1.0970\n","Iteration: 1/20, Step: 380/626, Loss: 1.2309\n","Iteration: 1/20, Step: 390/626, Loss: 1.1354\n","Iteration: 1/20, Step: 400/626, Loss: 1.4355\n","Iteration: 1/20, Step: 410/626, Loss: 1.5314\n","Iteration: 1/20, Step: 420/626, Loss: 1.1424\n","Iteration: 1/20, Step: 430/626, Loss: 1.2586\n","Iteration: 1/20, Step: 440/626, Loss: 1.2440\n","Iteration: 1/20, Step: 450/626, Loss: 1.0118\n","Iteration: 1/20, Step: 460/626, Loss: 1.5406\n","Iteration: 1/20, Step: 470/626, Loss: 0.9713\n","Iteration: 1/20, Step: 480/626, Loss: 0.9560\n","Iteration: 1/20, Step: 490/626, Loss: 1.1021\n","Iteration: 1/20, Step: 500/626, Loss: 1.2504\n","Iteration: 1/20, Step: 510/626, Loss: 1.1171\n","Iteration: 1/20, Step: 520/626, Loss: 1.1543\n","Iteration: 1/20, Step: 530/626, Loss: 1.0324\n","Iteration: 1/20, Step: 540/626, Loss: 1.3312\n","Iteration: 1/20, Step: 550/626, Loss: 1.0610\n","Iteration: 1/20, Step: 560/626, Loss: 1.2824\n","Iteration: 1/20, Step: 570/626, Loss: 1.2646\n","Iteration: 1/20, Step: 580/626, Loss: 1.2262\n","Iteration: 1/20, Step: 590/626, Loss: 1.1577\n","Iteration: 1/20, Step: 600/626, Loss: 1.4041\n","Iteration: 1/20, Step: 610/626, Loss: 1.2521\n","Iteration: 1/20, Step: 620/626, Loss: 1.2950\n","Iteration: 1/20, Test accuracy: 63.6667\n","Iteration: 2/20, Step: 10/626, Loss: 1.2898\n","Iteration: 2/20, Step: 20/626, Loss: 1.4974\n","Iteration: 2/20, Step: 30/626, Loss: 1.0760\n","Iteration: 2/20, Step: 40/626, Loss: 1.3957\n","Iteration: 2/20, Step: 50/626, Loss: 1.1001\n","Iteration: 2/20, Step: 60/626, Loss: 1.3467\n","Iteration: 2/20, Step: 70/626, Loss: 1.2563\n","Iteration: 2/20, Step: 80/626, Loss: 1.1027\n","Iteration: 2/20, Step: 90/626, Loss: 1.3008\n","Iteration: 2/20, Step: 100/626, Loss: 1.2196\n","Iteration: 2/20, Step: 110/626, Loss: 1.7517\n","Iteration: 2/20, Step: 120/626, Loss: 1.3431\n","Iteration: 2/20, Step: 130/626, Loss: 0.9372\n","Iteration: 2/20, Step: 140/626, Loss: 1.1330\n","Iteration: 2/20, Step: 150/626, Loss: 0.9687\n","Iteration: 2/20, Step: 160/626, Loss: 1.1180\n","Iteration: 2/20, Step: 170/626, Loss: 1.7391\n","Iteration: 2/20, Step: 180/626, Loss: 1.0583\n","Iteration: 2/20, Step: 190/626, Loss: 1.0593\n","Iteration: 2/20, Step: 200/626, Loss: 1.2127\n","Iteration: 2/20, Step: 210/626, Loss: 1.2002\n","Iteration: 2/20, Step: 220/626, Loss: 1.1450\n","Iteration: 2/20, Step: 230/626, Loss: 1.3755\n","Iteration: 2/20, Step: 240/626, Loss: 1.2302\n","Iteration: 2/20, Step: 250/626, Loss: 1.2037\n","Iteration: 2/20, Step: 260/626, Loss: 1.2043\n","Iteration: 2/20, Step: 270/626, Loss: 1.1086\n","Iteration: 2/20, Step: 280/626, Loss: 1.0154\n","Iteration: 2/20, Step: 290/626, Loss: 1.1272\n","Iteration: 2/20, Step: 300/626, Loss: 0.9967\n","Iteration: 2/20, Step: 310/626, Loss: 1.1023\n","Iteration: 2/20, Step: 320/626, Loss: 0.8983\n","Iteration: 2/20, Step: 330/626, Loss: 1.1468\n","Iteration: 2/20, Step: 340/626, Loss: 1.0971\n","Iteration: 2/20, Step: 350/626, Loss: 1.0583\n","Iteration: 2/20, Step: 360/626, Loss: 0.7592\n","Iteration: 2/20, Step: 370/626, Loss: 0.8727\n","Iteration: 2/20, Step: 380/626, Loss: 0.7699\n","Iteration: 2/20, Step: 390/626, Loss: 1.1043\n","Iteration: 2/20, Step: 400/626, Loss: 1.3328\n","Iteration: 2/20, Step: 410/626, Loss: 1.0825\n","Iteration: 2/20, Step: 420/626, Loss: 1.0981\n","Iteration: 2/20, Step: 430/626, Loss: 0.8825\n","Iteration: 2/20, Step: 440/626, Loss: 1.1061\n","Iteration: 2/20, Step: 450/626, Loss: 1.3556\n","Iteration: 2/20, Step: 460/626, Loss: 0.8450\n","Iteration: 2/20, Step: 470/626, Loss: 0.9843\n","Iteration: 2/20, Step: 480/626, Loss: 1.1326\n","Iteration: 2/20, Step: 490/626, Loss: 0.9991\n","Iteration: 2/20, Step: 500/626, Loss: 0.9837\n","Iteration: 2/20, Step: 510/626, Loss: 1.2653\n","Iteration: 2/20, Step: 520/626, Loss: 1.1777\n","Iteration: 2/20, Step: 530/626, Loss: 1.3178\n","Iteration: 2/20, Step: 540/626, Loss: 1.3670\n","Iteration: 2/20, Step: 550/626, Loss: 0.9892\n","Iteration: 2/20, Step: 560/626, Loss: 1.3770\n","Iteration: 2/20, Step: 570/626, Loss: 1.3747\n","Iteration: 2/20, Step: 580/626, Loss: 1.3315\n","Iteration: 2/20, Step: 590/626, Loss: 1.2625\n","Iteration: 2/20, Step: 600/626, Loss: 0.9272\n","Iteration: 2/20, Step: 610/626, Loss: 0.8890\n","Iteration: 2/20, Step: 620/626, Loss: 1.0000\n","Iteration: 2/20, Test accuracy: 66.5238\n","Iteration: 3/20, Step: 10/626, Loss: 0.8261\n","Iteration: 3/20, Step: 20/626, Loss: 1.1277\n","Iteration: 3/20, Step: 30/626, Loss: 0.9792\n","Iteration: 3/20, Step: 40/626, Loss: 0.9151\n","Iteration: 3/20, Step: 50/626, Loss: 1.0469\n","Iteration: 3/20, Step: 60/626, Loss: 1.3048\n","Iteration: 3/20, Step: 70/626, Loss: 0.7796\n","Iteration: 3/20, Step: 80/626, Loss: 0.9281\n","Iteration: 3/20, Step: 90/626, Loss: 0.9164\n","Iteration: 3/20, Step: 100/626, Loss: 0.9839\n","Iteration: 3/20, Step: 110/626, Loss: 1.3705\n","Iteration: 3/20, Step: 120/626, Loss: 0.8078\n","Iteration: 3/20, Step: 130/626, Loss: 0.8385\n","Iteration: 3/20, Step: 140/626, Loss: 1.0185\n","Iteration: 3/20, Step: 150/626, Loss: 1.0403\n","Iteration: 3/20, Step: 160/626, Loss: 0.9804\n","Iteration: 3/20, Step: 170/626, Loss: 0.8929\n","Iteration: 3/20, Step: 180/626, Loss: 0.9555\n","Iteration: 3/20, Step: 190/626, Loss: 0.8797\n","Iteration: 3/20, Step: 200/626, Loss: 0.8647\n","Iteration: 3/20, Step: 210/626, Loss: 1.0116\n","Iteration: 3/20, Step: 220/626, Loss: 0.7610\n","Iteration: 3/20, Step: 230/626, Loss: 0.8155\n","Iteration: 3/20, Step: 240/626, Loss: 0.8286\n","Iteration: 3/20, Step: 250/626, Loss: 0.9600\n","Iteration: 3/20, Step: 260/626, Loss: 1.0727\n","Iteration: 3/20, Step: 270/626, Loss: 0.8998\n","Iteration: 3/20, Step: 280/626, Loss: 0.6658\n","Iteration: 3/20, Step: 290/626, Loss: 0.9255\n","Iteration: 3/20, Step: 300/626, Loss: 1.0210\n","Iteration: 3/20, Step: 310/626, Loss: 1.1198\n","Iteration: 3/20, Step: 320/626, Loss: 0.9685\n","Iteration: 3/20, Step: 330/626, Loss: 0.7074\n","Iteration: 3/20, Step: 340/626, Loss: 0.7664\n","Iteration: 3/20, Step: 350/626, Loss: 0.9505\n","Iteration: 3/20, Step: 360/626, Loss: 1.0033\n","Iteration: 3/20, Step: 370/626, Loss: 0.9586\n","Iteration: 3/20, Step: 380/626, Loss: 1.2793\n","Iteration: 3/20, Step: 390/626, Loss: 0.9903\n","Iteration: 3/20, Step: 400/626, Loss: 0.8962\n","Iteration: 3/20, Step: 410/626, Loss: 0.9789\n","Iteration: 3/20, Step: 420/626, Loss: 0.9915\n","Iteration: 3/20, Step: 430/626, Loss: 1.1029\n","Iteration: 3/20, Step: 440/626, Loss: 1.0418\n","Iteration: 3/20, Step: 450/626, Loss: 0.9694\n","Iteration: 3/20, Step: 460/626, Loss: 0.8973\n","Iteration: 3/20, Step: 470/626, Loss: 0.6944\n","Iteration: 3/20, Step: 480/626, Loss: 0.8355\n","Iteration: 3/20, Step: 490/626, Loss: 0.7735\n","Iteration: 3/20, Step: 500/626, Loss: 0.7259\n","Iteration: 3/20, Step: 510/626, Loss: 0.9226\n","Iteration: 3/20, Step: 520/626, Loss: 0.8677\n","Iteration: 3/20, Step: 530/626, Loss: 0.8346\n","Iteration: 3/20, Step: 540/626, Loss: 1.1099\n","Iteration: 3/20, Step: 550/626, Loss: 0.9213\n","Iteration: 3/20, Step: 560/626, Loss: 1.1042\n","Iteration: 3/20, Step: 570/626, Loss: 1.0908\n","Iteration: 3/20, Step: 580/626, Loss: 0.8645\n","Iteration: 3/20, Step: 590/626, Loss: 1.0481\n","Iteration: 3/20, Step: 600/626, Loss: 0.9312\n","Iteration: 3/20, Step: 610/626, Loss: 0.8239\n","Iteration: 3/20, Step: 620/626, Loss: 0.8620\n","Iteration: 3/20, Test accuracy: 69.0476\n","Iteration: 4/20, Step: 10/626, Loss: 0.9884\n","Iteration: 4/20, Step: 20/626, Loss: 0.7109\n","Iteration: 4/20, Step: 30/626, Loss: 0.8770\n","Iteration: 4/20, Step: 40/626, Loss: 0.9679\n","Iteration: 4/20, Step: 50/626, Loss: 0.8460\n","Iteration: 4/20, Step: 60/626, Loss: 1.1797\n","Iteration: 4/20, Step: 70/626, Loss: 0.7305\n","Iteration: 4/20, Step: 80/626, Loss: 0.9419\n","Iteration: 4/20, Step: 90/626, Loss: 0.8877\n","Iteration: 4/20, Step: 100/626, Loss: 0.6973\n","Iteration: 4/20, Step: 110/626, Loss: 0.9443\n","Iteration: 4/20, Step: 120/626, Loss: 1.2424\n","Iteration: 4/20, Step: 130/626, Loss: 1.0621\n","Iteration: 4/20, Step: 140/626, Loss: 0.7813\n","Iteration: 4/20, Step: 150/626, Loss: 1.0323\n","Iteration: 4/20, Step: 160/626, Loss: 1.2975\n","Iteration: 4/20, Step: 170/626, Loss: 0.6840\n","Iteration: 4/20, Step: 180/626, Loss: 0.8081\n","Iteration: 4/20, Step: 190/626, Loss: 0.8491\n","Iteration: 4/20, Step: 200/626, Loss: 0.8990\n","Iteration: 4/20, Step: 210/626, Loss: 0.9475\n","Iteration: 4/20, Step: 220/626, Loss: 0.8945\n","Iteration: 4/20, Step: 230/626, Loss: 0.6953\n","Iteration: 4/20, Step: 240/626, Loss: 0.6263\n","Iteration: 4/20, Step: 250/626, Loss: 0.5729\n","Iteration: 4/20, Step: 260/626, Loss: 0.6671\n","Iteration: 4/20, Step: 270/626, Loss: 0.6965\n","Iteration: 4/20, Step: 280/626, Loss: 0.7042\n","Iteration: 4/20, Step: 290/626, Loss: 0.7167\n","Iteration: 4/20, Step: 300/626, Loss: 0.8059\n","Iteration: 4/20, Step: 310/626, Loss: 1.0425\n","Iteration: 4/20, Step: 320/626, Loss: 1.1129\n","Iteration: 4/20, Step: 330/626, Loss: 0.8098\n","Iteration: 4/20, Step: 340/626, Loss: 0.9218\n","Iteration: 4/20, Step: 350/626, Loss: 0.6514\n","Iteration: 4/20, Step: 360/626, Loss: 0.8375\n","Iteration: 4/20, Step: 370/626, Loss: 0.3815\n","Iteration: 4/20, Step: 380/626, Loss: 0.6693\n","Iteration: 4/20, Step: 390/626, Loss: 1.1420\n","Iteration: 4/20, Step: 400/626, Loss: 0.8932\n","Iteration: 4/20, Step: 410/626, Loss: 0.9579\n","Iteration: 4/20, Step: 420/626, Loss: 1.0523\n","Iteration: 4/20, Step: 430/626, Loss: 0.9595\n","Iteration: 4/20, Step: 440/626, Loss: 1.0270\n","Iteration: 4/20, Step: 450/626, Loss: 1.1692\n","Iteration: 4/20, Step: 460/626, Loss: 0.9468\n","Iteration: 4/20, Step: 470/626, Loss: 0.8652\n","Iteration: 4/20, Step: 480/626, Loss: 0.8810\n","Iteration: 4/20, Step: 490/626, Loss: 0.7682\n","Iteration: 4/20, Step: 500/626, Loss: 1.2553\n","Iteration: 4/20, Step: 510/626, Loss: 0.7986\n","Iteration: 4/20, Step: 520/626, Loss: 0.7491\n","Iteration: 4/20, Step: 530/626, Loss: 0.6720\n","Iteration: 4/20, Step: 540/626, Loss: 0.8425\n","Iteration: 4/20, Step: 550/626, Loss: 0.6424\n","Iteration: 4/20, Step: 560/626, Loss: 0.8979\n","Iteration: 4/20, Step: 570/626, Loss: 0.5776\n","Iteration: 4/20, Step: 580/626, Loss: 0.7411\n","Iteration: 4/20, Step: 590/626, Loss: 0.7812\n","Iteration: 4/20, Step: 600/626, Loss: 0.6689\n","Iteration: 4/20, Step: 610/626, Loss: 0.6633\n","Iteration: 4/20, Step: 620/626, Loss: 0.8438\n","Iteration: 4/20, Test accuracy: 69.6667\n","Iteration: 5/20, Step: 10/626, Loss: 0.8610\n","Iteration: 5/20, Step: 20/626, Loss: 0.4882\n","Iteration: 5/20, Step: 30/626, Loss: 0.6557\n","Iteration: 5/20, Step: 40/626, Loss: 0.6841\n","Iteration: 5/20, Step: 50/626, Loss: 1.0336\n","Iteration: 5/20, Step: 60/626, Loss: 0.4763\n","Iteration: 5/20, Step: 70/626, Loss: 0.9057\n","Iteration: 5/20, Step: 80/626, Loss: 0.9850\n","Iteration: 5/20, Step: 90/626, Loss: 0.9794\n","Iteration: 5/20, Step: 100/626, Loss: 1.1031\n","Iteration: 5/20, Step: 110/626, Loss: 0.8020\n","Iteration: 5/20, Step: 120/626, Loss: 0.5806\n","Iteration: 5/20, Step: 130/626, Loss: 0.8272\n","Iteration: 5/20, Step: 140/626, Loss: 0.8717\n","Iteration: 5/20, Step: 150/626, Loss: 1.1590\n","Iteration: 5/20, Step: 160/626, Loss: 0.7110\n","Iteration: 5/20, Step: 170/626, Loss: 0.7561\n","Iteration: 5/20, Step: 180/626, Loss: 0.7722\n","Iteration: 5/20, Step: 190/626, Loss: 0.4715\n","Iteration: 5/20, Step: 200/626, Loss: 0.9610\n","Iteration: 5/20, Step: 210/626, Loss: 0.6612\n","Iteration: 5/20, Step: 220/626, Loss: 0.5715\n","Iteration: 5/20, Step: 230/626, Loss: 0.6886\n","Iteration: 5/20, Step: 240/626, Loss: 0.5793\n","Iteration: 5/20, Step: 250/626, Loss: 0.6921\n","Iteration: 5/20, Step: 260/626, Loss: 0.4108\n","Iteration: 5/20, Step: 270/626, Loss: 0.5802\n","Iteration: 5/20, Step: 280/626, Loss: 1.1040\n","Iteration: 5/20, Step: 290/626, Loss: 0.6142\n","Iteration: 5/20, Step: 300/626, Loss: 0.6189\n","Iteration: 5/20, Step: 310/626, Loss: 0.7939\n","Iteration: 5/20, Step: 320/626, Loss: 0.6042\n","Iteration: 5/20, Step: 330/626, Loss: 0.7313\n","Iteration: 5/20, Step: 340/626, Loss: 0.8143\n","Iteration: 5/20, Step: 350/626, Loss: 0.5379\n","Iteration: 5/20, Step: 360/626, Loss: 0.8172\n","Iteration: 5/20, Step: 370/626, Loss: 0.5293\n","Iteration: 5/20, Step: 380/626, Loss: 0.6954\n","Iteration: 5/20, Step: 390/626, Loss: 0.9376\n","Iteration: 5/20, Step: 400/626, Loss: 0.9577\n","Iteration: 5/20, Step: 410/626, Loss: 0.6581\n","Iteration: 5/20, Step: 420/626, Loss: 0.8463\n","Iteration: 5/20, Step: 430/626, Loss: 0.7205\n","Iteration: 5/20, Step: 440/626, Loss: 0.5469\n","Iteration: 5/20, Step: 450/626, Loss: 0.8013\n","Iteration: 5/20, Step: 460/626, Loss: 0.8765\n","Iteration: 5/20, Step: 470/626, Loss: 0.8956\n","Iteration: 5/20, Step: 480/626, Loss: 1.0221\n","Iteration: 5/20, Step: 490/626, Loss: 0.5216\n","Iteration: 5/20, Step: 500/626, Loss: 0.9262\n","Iteration: 5/20, Step: 510/626, Loss: 0.6574\n","Iteration: 5/20, Step: 520/626, Loss: 0.7218\n","Iteration: 5/20, Step: 530/626, Loss: 0.4441\n","Iteration: 5/20, Step: 540/626, Loss: 0.3122\n","Iteration: 5/20, Step: 550/626, Loss: 0.8465\n","Iteration: 5/20, Step: 560/626, Loss: 0.9302\n","Iteration: 5/20, Step: 570/626, Loss: 0.4525\n","Iteration: 5/20, Step: 580/626, Loss: 0.7902\n","Iteration: 5/20, Step: 590/626, Loss: 0.8251\n","Iteration: 5/20, Step: 600/626, Loss: 0.9350\n","Iteration: 5/20, Step: 610/626, Loss: 0.5213\n","Iteration: 5/20, Step: 620/626, Loss: 0.5333\n","Iteration: 5/20, Test accuracy: 70.1905\n","Iteration: 6/20, Step: 10/626, Loss: 0.6959\n","Iteration: 6/20, Step: 20/626, Loss: 0.8302\n","Iteration: 6/20, Step: 30/626, Loss: 0.4924\n","Iteration: 6/20, Step: 40/626, Loss: 0.7126\n","Iteration: 6/20, Step: 50/626, Loss: 0.6906\n","Iteration: 6/20, Step: 60/626, Loss: 0.6729\n","Iteration: 6/20, Step: 70/626, Loss: 0.8931\n","Iteration: 6/20, Step: 80/626, Loss: 0.7517\n","Iteration: 6/20, Step: 90/626, Loss: 0.7843\n","Iteration: 6/20, Step: 100/626, Loss: 0.4087\n","Iteration: 6/20, Step: 110/626, Loss: 0.5398\n","Iteration: 6/20, Step: 120/626, Loss: 0.3986\n","Iteration: 6/20, Step: 130/626, Loss: 0.8485\n","Iteration: 6/20, Step: 140/626, Loss: 0.8288\n","Iteration: 6/20, Step: 150/626, Loss: 0.7266\n","Iteration: 6/20, Step: 160/626, Loss: 0.5121\n","Iteration: 6/20, Step: 170/626, Loss: 0.3297\n","Iteration: 6/20, Step: 180/626, Loss: 0.7734\n","Iteration: 6/20, Step: 190/626, Loss: 0.6673\n","Iteration: 6/20, Step: 200/626, Loss: 0.5159\n","Iteration: 6/20, Step: 210/626, Loss: 0.8003\n","Iteration: 6/20, Step: 220/626, Loss: 1.0258\n","Iteration: 6/20, Step: 230/626, Loss: 0.7293\n","Iteration: 6/20, Step: 240/626, Loss: 1.0212\n","Iteration: 6/20, Step: 250/626, Loss: 0.4028\n","Iteration: 6/20, Step: 260/626, Loss: 0.8988\n","Iteration: 6/20, Step: 270/626, Loss: 0.7915\n","Iteration: 6/20, Step: 280/626, Loss: 0.5860\n","Iteration: 6/20, Step: 290/626, Loss: 0.6337\n","Iteration: 6/20, Step: 300/626, Loss: 0.8080\n","Iteration: 6/20, Step: 310/626, Loss: 0.8274\n","Iteration: 6/20, Step: 320/626, Loss: 0.7227\n","Iteration: 6/20, Step: 330/626, Loss: 0.6838\n","Iteration: 6/20, Step: 340/626, Loss: 0.5529\n","Iteration: 6/20, Step: 350/626, Loss: 0.5065\n","Iteration: 6/20, Step: 360/626, Loss: 0.6541\n","Iteration: 6/20, Step: 370/626, Loss: 0.6106\n","Iteration: 6/20, Step: 380/626, Loss: 0.8102\n","Iteration: 6/20, Step: 390/626, Loss: 0.5772\n","Iteration: 6/20, Step: 400/626, Loss: 0.6698\n","Iteration: 6/20, Step: 410/626, Loss: 0.8629\n","Iteration: 6/20, Step: 420/626, Loss: 0.9381\n","Iteration: 6/20, Step: 430/626, Loss: 0.7886\n","Iteration: 6/20, Step: 440/626, Loss: 0.7920\n","Iteration: 6/20, Step: 450/626, Loss: 0.8515\n","Iteration: 6/20, Step: 460/626, Loss: 0.6822\n","Iteration: 6/20, Step: 470/626, Loss: 0.8854\n","Iteration: 6/20, Step: 480/626, Loss: 0.7674\n","Iteration: 6/20, Step: 490/626, Loss: 0.8772\n","Iteration: 6/20, Step: 500/626, Loss: 0.6434\n","Iteration: 6/20, Step: 510/626, Loss: 0.6265\n","Iteration: 6/20, Step: 520/626, Loss: 1.0288\n","Iteration: 6/20, Step: 530/626, Loss: 0.6088\n","Iteration: 6/20, Step: 540/626, Loss: 0.4387\n","Iteration: 6/20, Step: 550/626, Loss: 0.7738\n","Iteration: 6/20, Step: 560/626, Loss: 0.5785\n","Iteration: 6/20, Step: 570/626, Loss: 0.6562\n","Iteration: 6/20, Step: 580/626, Loss: 0.9017\n","Iteration: 6/20, Step: 590/626, Loss: 0.4556\n","Iteration: 6/20, Step: 600/626, Loss: 0.6930\n","Iteration: 6/20, Step: 610/626, Loss: 0.7834\n","Iteration: 6/20, Step: 620/626, Loss: 0.8392\n","Iteration: 6/20, Test accuracy: 71.6190\n","Iteration: 7/20, Step: 10/626, Loss: 0.5060\n","Iteration: 7/20, Step: 20/626, Loss: 0.7402\n","Iteration: 7/20, Step: 30/626, Loss: 0.5606\n","Iteration: 7/20, Step: 40/626, Loss: 0.6733\n","Iteration: 7/20, Step: 50/626, Loss: 0.5564\n","Iteration: 7/20, Step: 60/626, Loss: 0.5760\n","Iteration: 7/20, Step: 70/626, Loss: 0.7203\n","Iteration: 7/20, Step: 80/626, Loss: 0.5023\n","Iteration: 7/20, Step: 90/626, Loss: 0.7591\n","Iteration: 7/20, Step: 100/626, Loss: 0.5029\n","Iteration: 7/20, Step: 110/626, Loss: 0.5380\n","Iteration: 7/20, Step: 120/626, Loss: 0.4934\n","Iteration: 7/20, Step: 130/626, Loss: 0.6134\n","Iteration: 7/20, Step: 140/626, Loss: 0.4964\n","Iteration: 7/20, Step: 150/626, Loss: 0.7669\n","Iteration: 7/20, Step: 160/626, Loss: 0.7041\n","Iteration: 7/20, Step: 170/626, Loss: 0.3663\n","Iteration: 7/20, Step: 180/626, Loss: 0.6344\n","Iteration: 7/20, Step: 190/626, Loss: 0.6700\n","Iteration: 7/20, Step: 200/626, Loss: 0.7000\n","Iteration: 7/20, Step: 210/626, Loss: 0.7912\n","Iteration: 7/20, Step: 220/626, Loss: 0.5279\n","Iteration: 7/20, Step: 230/626, Loss: 0.8545\n","Iteration: 7/20, Step: 240/626, Loss: 0.9649\n","Iteration: 7/20, Step: 250/626, Loss: 0.6088\n","Iteration: 7/20, Step: 260/626, Loss: 1.1245\n","Iteration: 7/20, Step: 270/626, Loss: 0.6334\n","Iteration: 7/20, Step: 280/626, Loss: 0.7392\n","Iteration: 7/20, Step: 290/626, Loss: 0.4863\n","Iteration: 7/20, Step: 300/626, Loss: 0.5431\n","Iteration: 7/20, Step: 310/626, Loss: 0.5339\n","Iteration: 7/20, Step: 320/626, Loss: 0.7615\n","Iteration: 7/20, Step: 330/626, Loss: 0.6535\n","Iteration: 7/20, Step: 340/626, Loss: 0.8407\n","Iteration: 7/20, Step: 350/626, Loss: 0.4735\n","Iteration: 7/20, Step: 360/626, Loss: 0.5633\n","Iteration: 7/20, Step: 370/626, Loss: 0.4564\n","Iteration: 7/20, Step: 380/626, Loss: 0.8079\n","Iteration: 7/20, Step: 390/626, Loss: 0.5395\n","Iteration: 7/20, Step: 400/626, Loss: 0.5523\n","Iteration: 7/20, Step: 410/626, Loss: 0.6645\n","Iteration: 7/20, Step: 420/626, Loss: 0.7014\n","Iteration: 7/20, Step: 430/626, Loss: 0.5997\n","Iteration: 7/20, Step: 440/626, Loss: 0.4976\n","Iteration: 7/20, Step: 450/626, Loss: 0.7222\n","Iteration: 7/20, Step: 460/626, Loss: 0.7005\n","Iteration: 7/20, Step: 470/626, Loss: 0.7359\n","Iteration: 7/20, Step: 480/626, Loss: 0.4068\n","Iteration: 7/20, Step: 490/626, Loss: 0.3442\n","Iteration: 7/20, Step: 500/626, Loss: 0.6486\n","Iteration: 7/20, Step: 510/626, Loss: 0.6046\n","Iteration: 7/20, Step: 520/626, Loss: 0.6275\n","Iteration: 7/20, Step: 530/626, Loss: 0.6589\n","Iteration: 7/20, Step: 540/626, Loss: 0.7545\n","Iteration: 7/20, Step: 550/626, Loss: 0.6115\n","Iteration: 7/20, Step: 560/626, Loss: 0.5615\n","Iteration: 7/20, Step: 570/626, Loss: 0.8932\n","Iteration: 7/20, Step: 580/626, Loss: 0.4957\n","Iteration: 7/20, Step: 590/626, Loss: 0.4189\n","Iteration: 7/20, Step: 600/626, Loss: 0.9311\n","Iteration: 7/20, Step: 610/626, Loss: 0.7547\n","Iteration: 7/20, Step: 620/626, Loss: 0.9015\n","Iteration: 7/20, Test accuracy: 71.6190\n","Iteration: 8/20, Step: 10/626, Loss: 0.3227\n","Iteration: 8/20, Step: 20/626, Loss: 0.5831\n","Iteration: 8/20, Step: 30/626, Loss: 0.5122\n","Iteration: 8/20, Step: 40/626, Loss: 0.4949\n","Iteration: 8/20, Step: 50/626, Loss: 0.5303\n","Iteration: 8/20, Step: 60/626, Loss: 0.6164\n","Iteration: 8/20, Step: 70/626, Loss: 1.1457\n","Iteration: 8/20, Step: 80/626, Loss: 0.6160\n","Iteration: 8/20, Step: 90/626, Loss: 0.4578\n","Iteration: 8/20, Step: 100/626, Loss: 0.7693\n","Iteration: 8/20, Step: 110/626, Loss: 0.5612\n","Iteration: 8/20, Step: 120/626, Loss: 0.7120\n","Iteration: 8/20, Step: 130/626, Loss: 0.4927\n","Iteration: 8/20, Step: 140/626, Loss: 0.5648\n","Iteration: 8/20, Step: 150/626, Loss: 0.4787\n","Iteration: 8/20, Step: 160/626, Loss: 0.6132\n","Iteration: 8/20, Step: 170/626, Loss: 0.5844\n","Iteration: 8/20, Step: 180/626, Loss: 0.7851\n","Iteration: 8/20, Step: 190/626, Loss: 0.5542\n","Iteration: 8/20, Step: 200/626, Loss: 0.8802\n","Iteration: 8/20, Step: 210/626, Loss: 0.4122\n","Iteration: 8/20, Step: 220/626, Loss: 0.7756\n","Iteration: 8/20, Step: 230/626, Loss: 0.4662\n","Iteration: 8/20, Step: 240/626, Loss: 0.6077\n","Iteration: 8/20, Step: 250/626, Loss: 0.5429\n","Iteration: 8/20, Step: 260/626, Loss: 0.6332\n","Iteration: 8/20, Step: 270/626, Loss: 0.4842\n","Iteration: 8/20, Step: 280/626, Loss: 0.4223\n","Iteration: 8/20, Step: 290/626, Loss: 0.5899\n","Iteration: 8/20, Step: 300/626, Loss: 0.7128\n","Iteration: 8/20, Step: 310/626, Loss: 0.5741\n","Iteration: 8/20, Step: 320/626, Loss: 0.5819\n","Iteration: 8/20, Step: 330/626, Loss: 0.7075\n","Iteration: 8/20, Step: 340/626, Loss: 0.7597\n","Iteration: 8/20, Step: 350/626, Loss: 0.5076\n","Iteration: 8/20, Step: 360/626, Loss: 0.4211\n","Iteration: 8/20, Step: 370/626, Loss: 0.6663\n","Iteration: 8/20, Step: 380/626, Loss: 0.5455\n","Iteration: 8/20, Step: 390/626, Loss: 0.7532\n","Iteration: 8/20, Step: 400/626, Loss: 0.3194\n","Iteration: 8/20, Step: 410/626, Loss: 0.5340\n","Iteration: 8/20, Step: 420/626, Loss: 0.6100\n","Iteration: 8/20, Step: 430/626, Loss: 0.9625\n","Iteration: 8/20, Step: 440/626, Loss: 0.8049\n","Iteration: 8/20, Step: 450/626, Loss: 0.5893\n","Iteration: 8/20, Step: 460/626, Loss: 0.2917\n","Iteration: 8/20, Step: 470/626, Loss: 0.4347\n","Iteration: 8/20, Step: 480/626, Loss: 0.4796\n","Iteration: 8/20, Step: 490/626, Loss: 0.3905\n","Iteration: 8/20, Step: 500/626, Loss: 0.3165\n","Iteration: 8/20, Step: 510/626, Loss: 0.3698\n","Iteration: 8/20, Step: 520/626, Loss: 0.8657\n","Iteration: 8/20, Step: 530/626, Loss: 0.6625\n","Iteration: 8/20, Step: 540/626, Loss: 0.4551\n","Iteration: 8/20, Step: 550/626, Loss: 0.5917\n","Iteration: 8/20, Step: 560/626, Loss: 0.5452\n","Iteration: 8/20, Step: 570/626, Loss: 0.6173\n","Iteration: 8/20, Step: 580/626, Loss: 0.4130\n","Iteration: 8/20, Step: 590/626, Loss: 0.4259\n","Iteration: 8/20, Step: 600/626, Loss: 0.7257\n","Iteration: 8/20, Step: 610/626, Loss: 0.6232\n","Iteration: 8/20, Step: 620/626, Loss: 0.5962\n","Iteration: 8/20, Test accuracy: 71.9524\n","Iteration: 9/20, Step: 10/626, Loss: 0.5084\n","Iteration: 9/20, Step: 20/626, Loss: 0.7384\n","Iteration: 9/20, Step: 30/626, Loss: 0.7271\n","Iteration: 9/20, Step: 40/626, Loss: 0.3246\n","Iteration: 9/20, Step: 50/626, Loss: 0.2245\n","Iteration: 9/20, Step: 60/626, Loss: 0.5152\n","Iteration: 9/20, Step: 70/626, Loss: 0.2326\n","Iteration: 9/20, Step: 80/626, Loss: 0.6245\n","Iteration: 9/20, Step: 90/626, Loss: 0.6685\n","Iteration: 9/20, Step: 100/626, Loss: 0.3604\n","Iteration: 9/20, Step: 110/626, Loss: 0.5789\n","Iteration: 9/20, Step: 120/626, Loss: 0.3422\n","Iteration: 9/20, Step: 130/626, Loss: 0.3781\n","Iteration: 9/20, Step: 140/626, Loss: 0.6913\n","Iteration: 9/20, Step: 150/626, Loss: 0.4909\n","Iteration: 9/20, Step: 160/626, Loss: 0.7693\n","Iteration: 9/20, Step: 170/626, Loss: 0.5592\n","Iteration: 9/20, Step: 180/626, Loss: 0.6150\n","Iteration: 9/20, Step: 190/626, Loss: 0.6110\n","Iteration: 9/20, Step: 200/626, Loss: 0.6096\n","Iteration: 9/20, Step: 210/626, Loss: 0.5085\n","Iteration: 9/20, Step: 220/626, Loss: 0.7122\n","Iteration: 9/20, Step: 230/626, Loss: 0.6336\n","Iteration: 9/20, Step: 240/626, Loss: 0.3913\n","Iteration: 9/20, Step: 250/626, Loss: 0.5832\n","Iteration: 9/20, Step: 260/626, Loss: 0.7856\n","Iteration: 9/20, Step: 270/626, Loss: 0.5388\n","Iteration: 9/20, Step: 280/626, Loss: 0.4860\n","Iteration: 9/20, Step: 290/626, Loss: 0.4291\n","Iteration: 9/20, Step: 300/626, Loss: 0.6150\n","Iteration: 9/20, Step: 310/626, Loss: 0.5067\n","Iteration: 9/20, Step: 320/626, Loss: 0.9559\n","Iteration: 9/20, Step: 330/626, Loss: 0.6083\n","Iteration: 9/20, Step: 340/626, Loss: 0.3718\n","Iteration: 9/20, Step: 350/626, Loss: 0.5216\n","Iteration: 9/20, Step: 360/626, Loss: 0.9773\n","Iteration: 9/20, Step: 370/626, Loss: 0.7552\n","Iteration: 9/20, Step: 380/626, Loss: 0.6844\n","Iteration: 9/20, Step: 390/626, Loss: 0.8060\n","Iteration: 9/20, Step: 400/626, Loss: 0.9740\n","Iteration: 9/20, Step: 410/626, Loss: 0.7626\n","Iteration: 9/20, Step: 420/626, Loss: 0.5770\n","Iteration: 9/20, Step: 430/626, Loss: 0.8848\n","Iteration: 9/20, Step: 440/626, Loss: 0.3700\n","Iteration: 9/20, Step: 450/626, Loss: 0.6928\n","Iteration: 9/20, Step: 460/626, Loss: 0.5654\n","Iteration: 9/20, Step: 470/626, Loss: 0.4382\n","Iteration: 9/20, Step: 480/626, Loss: 0.4606\n","Iteration: 9/20, Step: 490/626, Loss: 0.4849\n","Iteration: 9/20, Step: 500/626, Loss: 0.5404\n","Iteration: 9/20, Step: 510/626, Loss: 0.5724\n","Iteration: 9/20, Step: 520/626, Loss: 0.5796\n","Iteration: 9/20, Step: 530/626, Loss: 0.3957\n","Iteration: 9/20, Step: 540/626, Loss: 0.5255\n","Iteration: 9/20, Step: 550/626, Loss: 0.5979\n","Iteration: 9/20, Step: 560/626, Loss: 0.5799\n","Iteration: 9/20, Step: 570/626, Loss: 0.5535\n","Iteration: 9/20, Step: 580/626, Loss: 0.7560\n","Iteration: 9/20, Step: 590/626, Loss: 0.5690\n","Iteration: 9/20, Step: 600/626, Loss: 0.4934\n","Iteration: 9/20, Step: 610/626, Loss: 0.2214\n","Iteration: 9/20, Step: 620/626, Loss: 0.7462\n","Iteration: 9/20, Test accuracy: 72.7143\n","Iteration: 10/20, Step: 10/626, Loss: 0.5952\n","Iteration: 10/20, Step: 20/626, Loss: 0.4180\n","Iteration: 10/20, Step: 30/626, Loss: 0.3729\n","Iteration: 10/20, Step: 40/626, Loss: 0.7629\n","Iteration: 10/20, Step: 50/626, Loss: 0.5927\n","Iteration: 10/20, Step: 60/626, Loss: 0.7451\n","Iteration: 10/20, Step: 70/626, Loss: 0.5668\n","Iteration: 10/20, Step: 80/626, Loss: 0.4858\n","Iteration: 10/20, Step: 90/626, Loss: 0.5142\n","Iteration: 10/20, Step: 100/626, Loss: 0.4462\n","Iteration: 10/20, Step: 110/626, Loss: 0.7722\n","Iteration: 10/20, Step: 120/626, Loss: 0.6102\n","Iteration: 10/20, Step: 130/626, Loss: 0.7400\n","Iteration: 10/20, Step: 140/626, Loss: 0.5134\n","Iteration: 10/20, Step: 150/626, Loss: 0.4745\n","Iteration: 10/20, Step: 160/626, Loss: 0.5108\n","Iteration: 10/20, Step: 170/626, Loss: 0.5675\n","Iteration: 10/20, Step: 180/626, Loss: 0.5373\n","Iteration: 10/20, Step: 190/626, Loss: 0.8492\n","Iteration: 10/20, Step: 200/626, Loss: 0.3120\n","Iteration: 10/20, Step: 210/626, Loss: 0.3937\n","Iteration: 10/20, Step: 220/626, Loss: 1.0211\n","Iteration: 10/20, Step: 230/626, Loss: 0.4905\n","Iteration: 10/20, Step: 240/626, Loss: 0.8979\n","Iteration: 10/20, Step: 250/626, Loss: 0.5804\n","Iteration: 10/20, Step: 260/626, Loss: 0.3226\n","Iteration: 10/20, Step: 270/626, Loss: 0.6041\n","Iteration: 10/20, Step: 280/626, Loss: 0.2714\n","Iteration: 10/20, Step: 290/626, Loss: 0.5802\n","Iteration: 10/20, Step: 300/626, Loss: 0.3210\n","Iteration: 10/20, Step: 310/626, Loss: 0.6775\n","Iteration: 10/20, Step: 320/626, Loss: 0.5553\n","Iteration: 10/20, Step: 330/626, Loss: 0.6048\n","Iteration: 10/20, Step: 340/626, Loss: 0.3397\n","Iteration: 10/20, Step: 350/626, Loss: 0.4074\n","Iteration: 10/20, Step: 360/626, Loss: 0.6404\n","Iteration: 10/20, Step: 370/626, Loss: 0.3807\n","Iteration: 10/20, Step: 380/626, Loss: 0.5563\n","Iteration: 10/20, Step: 390/626, Loss: 0.7084\n","Iteration: 10/20, Step: 400/626, Loss: 0.7909\n","Iteration: 10/20, Step: 410/626, Loss: 0.4514\n","Iteration: 10/20, Step: 420/626, Loss: 0.5658\n","Iteration: 10/20, Step: 430/626, Loss: 0.4498\n","Iteration: 10/20, Step: 440/626, Loss: 0.7191\n","Iteration: 10/20, Step: 450/626, Loss: 0.4463\n","Iteration: 10/20, Step: 460/626, Loss: 0.7857\n","Iteration: 10/20, Step: 470/626, Loss: 0.4052\n","Iteration: 10/20, Step: 480/626, Loss: 0.9127\n","Iteration: 10/20, Step: 490/626, Loss: 0.5011\n","Iteration: 10/20, Step: 500/626, Loss: 0.4632\n","Iteration: 10/20, Step: 510/626, Loss: 0.5138\n","Iteration: 10/20, Step: 520/626, Loss: 0.3630\n","Iteration: 10/20, Step: 530/626, Loss: 0.6684\n","Iteration: 10/20, Step: 540/626, Loss: 0.4789\n","Iteration: 10/20, Step: 550/626, Loss: 0.4738\n","Iteration: 10/20, Step: 560/626, Loss: 0.4973\n","Iteration: 10/20, Step: 570/626, Loss: 0.4439\n","Iteration: 10/20, Step: 580/626, Loss: 0.6650\n","Iteration: 10/20, Step: 590/626, Loss: 0.5373\n","Iteration: 10/20, Step: 600/626, Loss: 1.0926\n","Iteration: 10/20, Step: 610/626, Loss: 0.3470\n","Iteration: 10/20, Step: 620/626, Loss: 0.7017\n","Iteration: 10/20, Test accuracy: 73.3333\n","Iteration: 11/20, Step: 10/626, Loss: 0.5703\n","Iteration: 11/20, Step: 20/626, Loss: 0.2723\n","Iteration: 11/20, Step: 30/626, Loss: 0.7558\n","Iteration: 11/20, Step: 40/626, Loss: 0.5032\n","Iteration: 11/20, Step: 50/626, Loss: 0.5486\n","Iteration: 11/20, Step: 60/626, Loss: 0.2019\n","Iteration: 11/20, Step: 70/626, Loss: 0.5425\n","Iteration: 11/20, Step: 80/626, Loss: 0.8712\n","Iteration: 11/20, Step: 90/626, Loss: 0.3933\n","Iteration: 11/20, Step: 100/626, Loss: 0.6826\n","Iteration: 11/20, Step: 110/626, Loss: 0.4918\n","Iteration: 11/20, Step: 120/626, Loss: 0.8283\n","Iteration: 11/20, Step: 130/626, Loss: 0.5642\n","Iteration: 11/20, Step: 140/626, Loss: 0.4797\n","Iteration: 11/20, Step: 150/626, Loss: 0.4194\n","Iteration: 11/20, Step: 160/626, Loss: 0.6396\n","Iteration: 11/20, Step: 170/626, Loss: 0.3600\n","Iteration: 11/20, Step: 180/626, Loss: 0.6077\n","Iteration: 11/20, Step: 190/626, Loss: 0.3835\n","Iteration: 11/20, Step: 200/626, Loss: 0.6051\n","Iteration: 11/20, Step: 210/626, Loss: 0.3653\n","Iteration: 11/20, Step: 220/626, Loss: 0.5716\n","Iteration: 11/20, Step: 230/626, Loss: 0.8352\n","Iteration: 11/20, Step: 240/626, Loss: 0.5457\n","Iteration: 11/20, Step: 250/626, Loss: 0.6427\n","Iteration: 11/20, Step: 260/626, Loss: 0.5174\n","Iteration: 11/20, Step: 270/626, Loss: 0.7499\n","Iteration: 11/20, Step: 280/626, Loss: 0.5222\n","Iteration: 11/20, Step: 290/626, Loss: 0.5575\n","Iteration: 11/20, Step: 300/626, Loss: 0.6420\n","Iteration: 11/20, Step: 310/626, Loss: 0.5592\n","Iteration: 11/20, Step: 320/626, Loss: 0.6181\n","Iteration: 11/20, Step: 330/626, Loss: 0.4663\n","Iteration: 11/20, Step: 340/626, Loss: 0.4812\n","Iteration: 11/20, Step: 350/626, Loss: 0.8980\n","Iteration: 11/20, Step: 360/626, Loss: 0.3719\n","Iteration: 11/20, Step: 370/626, Loss: 0.5820\n","Iteration: 11/20, Step: 380/626, Loss: 0.7208\n","Iteration: 11/20, Step: 390/626, Loss: 0.7671\n","Iteration: 11/20, Step: 400/626, Loss: 0.5230\n","Iteration: 11/20, Step: 410/626, Loss: 0.3632\n","Iteration: 11/20, Step: 420/626, Loss: 0.6714\n","Iteration: 11/20, Step: 430/626, Loss: 0.6045\n","Iteration: 11/20, Step: 440/626, Loss: 0.4162\n","Iteration: 11/20, Step: 450/626, Loss: 0.5628\n","Iteration: 11/20, Step: 460/626, Loss: 0.6707\n","Iteration: 11/20, Step: 470/626, Loss: 0.9695\n","Iteration: 11/20, Step: 480/626, Loss: 0.7014\n","Iteration: 11/20, Step: 490/626, Loss: 0.6533\n","Iteration: 11/20, Step: 500/626, Loss: 0.5361\n","Iteration: 11/20, Step: 510/626, Loss: 0.4262\n","Iteration: 11/20, Step: 520/626, Loss: 0.4404\n","Iteration: 11/20, Step: 530/626, Loss: 0.4637\n","Iteration: 11/20, Step: 540/626, Loss: 0.6138\n","Iteration: 11/20, Step: 550/626, Loss: 0.6293\n","Iteration: 11/20, Step: 560/626, Loss: 0.5035\n","Iteration: 11/20, Step: 570/626, Loss: 0.3889\n","Iteration: 11/20, Step: 580/626, Loss: 0.6045\n","Iteration: 11/20, Step: 590/626, Loss: 0.6220\n","Iteration: 11/20, Step: 600/626, Loss: 0.3068\n","Iteration: 11/20, Step: 610/626, Loss: 0.5442\n","Iteration: 11/20, Step: 620/626, Loss: 0.3803\n","Iteration: 11/20, Test accuracy: 73.7619\n","Iteration: 12/20, Step: 10/626, Loss: 0.5918\n","Iteration: 12/20, Step: 20/626, Loss: 0.3036\n","Iteration: 12/20, Step: 30/626, Loss: 0.2686\n","Iteration: 12/20, Step: 40/626, Loss: 0.4555\n","Iteration: 12/20, Step: 50/626, Loss: 0.4029\n","Iteration: 12/20, Step: 60/626, Loss: 0.4594\n","Iteration: 12/20, Step: 70/626, Loss: 0.5003\n","Iteration: 12/20, Step: 80/626, Loss: 0.6628\n","Iteration: 12/20, Step: 90/626, Loss: 0.6337\n","Iteration: 12/20, Step: 100/626, Loss: 0.5209\n","Iteration: 12/20, Step: 110/626, Loss: 0.3717\n","Iteration: 12/20, Step: 120/626, Loss: 0.4284\n","Iteration: 12/20, Step: 130/626, Loss: 0.2633\n","Iteration: 12/20, Step: 140/626, Loss: 0.3229\n","Iteration: 12/20, Step: 150/626, Loss: 0.5053\n","Iteration: 12/20, Step: 160/626, Loss: 0.4162\n","Iteration: 12/20, Step: 170/626, Loss: 0.6727\n","Iteration: 12/20, Step: 180/626, Loss: 0.4936\n","Iteration: 12/20, Step: 190/626, Loss: 0.4225\n","Iteration: 12/20, Step: 200/626, Loss: 0.5751\n","Iteration: 12/20, Step: 210/626, Loss: 0.4675\n","Iteration: 12/20, Step: 220/626, Loss: 0.4213\n","Iteration: 12/20, Step: 230/626, Loss: 0.4922\n","Iteration: 12/20, Step: 240/626, Loss: 0.6444\n","Iteration: 12/20, Step: 250/626, Loss: 0.3112\n","Iteration: 12/20, Step: 260/626, Loss: 0.5650\n","Iteration: 12/20, Step: 270/626, Loss: 0.7156\n","Iteration: 12/20, Step: 280/626, Loss: 0.7148\n","Iteration: 12/20, Step: 290/626, Loss: 0.4132\n","Iteration: 12/20, Step: 300/626, Loss: 0.6646\n","Iteration: 12/20, Step: 310/626, Loss: 0.4413\n","Iteration: 12/20, Step: 320/626, Loss: 0.2659\n","Iteration: 12/20, Step: 330/626, Loss: 0.5188\n","Iteration: 12/20, Step: 340/626, Loss: 0.3825\n","Iteration: 12/20, Step: 350/626, Loss: 0.4429\n","Iteration: 12/20, Step: 360/626, Loss: 0.5228\n","Iteration: 12/20, Step: 370/626, Loss: 0.6458\n","Iteration: 12/20, Step: 380/626, Loss: 0.5283\n","Iteration: 12/20, Step: 390/626, Loss: 0.5218\n","Iteration: 12/20, Step: 400/626, Loss: 0.2963\n","Iteration: 12/20, Step: 410/626, Loss: 0.4894\n","Iteration: 12/20, Step: 420/626, Loss: 0.3748\n","Iteration: 12/20, Step: 430/626, Loss: 0.4813\n","Iteration: 12/20, Step: 440/626, Loss: 0.3871\n","Iteration: 12/20, Step: 450/626, Loss: 0.5470\n","Iteration: 12/20, Step: 460/626, Loss: 0.4044\n","Iteration: 12/20, Step: 470/626, Loss: 0.6166\n","Iteration: 12/20, Step: 480/626, Loss: 0.4203\n","Iteration: 12/20, Step: 490/626, Loss: 0.3851\n","Iteration: 12/20, Step: 500/626, Loss: 0.3196\n","Iteration: 12/20, Step: 510/626, Loss: 0.4619\n","Iteration: 12/20, Step: 520/626, Loss: 0.3311\n","Iteration: 12/20, Step: 530/626, Loss: 0.5618\n","Iteration: 12/20, Step: 540/626, Loss: 0.4604\n","Iteration: 12/20, Step: 550/626, Loss: 0.4781\n","Iteration: 12/20, Step: 560/626, Loss: 0.7686\n","Iteration: 12/20, Step: 570/626, Loss: 0.2664\n","Iteration: 12/20, Step: 580/626, Loss: 0.6509\n","Iteration: 12/20, Step: 590/626, Loss: 0.6734\n","Iteration: 12/20, Step: 600/626, Loss: 0.3779\n","Iteration: 12/20, Step: 610/626, Loss: 0.5153\n","Iteration: 12/20, Step: 620/626, Loss: 0.8426\n","Iteration: 12/20, Test accuracy: 73.2381\n","Iteration: 13/20, Step: 10/626, Loss: 0.3323\n","Iteration: 13/20, Step: 20/626, Loss: 0.8509\n","Iteration: 13/20, Step: 30/626, Loss: 0.4189\n","Iteration: 13/20, Step: 40/626, Loss: 0.4714\n","Iteration: 13/20, Step: 50/626, Loss: 0.1884\n","Iteration: 13/20, Step: 60/626, Loss: 0.2548\n","Iteration: 13/20, Step: 70/626, Loss: 0.5663\n","Iteration: 13/20, Step: 80/626, Loss: 0.5524\n","Iteration: 13/20, Step: 90/626, Loss: 0.4353\n","Iteration: 13/20, Step: 100/626, Loss: 0.5261\n","Iteration: 13/20, Step: 110/626, Loss: 0.3309\n","Iteration: 13/20, Step: 120/626, Loss: 0.6561\n","Iteration: 13/20, Step: 130/626, Loss: 0.6826\n","Iteration: 13/20, Step: 140/626, Loss: 0.6577\n","Iteration: 13/20, Step: 150/626, Loss: 0.3160\n","Iteration: 13/20, Step: 160/626, Loss: 0.3871\n","Iteration: 13/20, Step: 170/626, Loss: 0.5947\n","Iteration: 13/20, Step: 180/626, Loss: 0.5180\n","Iteration: 13/20, Step: 190/626, Loss: 0.4041\n","Iteration: 13/20, Step: 200/626, Loss: 0.5064\n","Iteration: 13/20, Step: 210/626, Loss: 0.4107\n","Iteration: 13/20, Step: 220/626, Loss: 0.3974\n","Iteration: 13/20, Step: 230/626, Loss: 0.3297\n","Iteration: 13/20, Step: 240/626, Loss: 0.4751\n","Iteration: 13/20, Step: 250/626, Loss: 0.5490\n","Iteration: 13/20, Step: 260/626, Loss: 0.5172\n","Iteration: 13/20, Step: 270/626, Loss: 0.3726\n","Iteration: 13/20, Step: 280/626, Loss: 0.4185\n","Iteration: 13/20, Step: 290/626, Loss: 0.4402\n","Iteration: 13/20, Step: 300/626, Loss: 0.7084\n","Iteration: 13/20, Step: 310/626, Loss: 0.5327\n","Iteration: 13/20, Step: 320/626, Loss: 0.5333\n","Iteration: 13/20, Step: 330/626, Loss: 0.4113\n","Iteration: 13/20, Step: 340/626, Loss: 0.5759\n","Iteration: 13/20, Step: 350/626, Loss: 0.5340\n","Iteration: 13/20, Step: 360/626, Loss: 0.4035\n","Iteration: 13/20, Step: 370/626, Loss: 0.4238\n","Iteration: 13/20, Step: 380/626, Loss: 0.4796\n","Iteration: 13/20, Step: 390/626, Loss: 0.1293\n","Iteration: 13/20, Step: 400/626, Loss: 0.5634\n","Iteration: 13/20, Step: 410/626, Loss: 0.6657\n","Iteration: 13/20, Step: 420/626, Loss: 0.4520\n","Iteration: 13/20, Step: 430/626, Loss: 0.4571\n","Iteration: 13/20, Step: 440/626, Loss: 0.4896\n","Iteration: 13/20, Step: 450/626, Loss: 0.9656\n","Iteration: 13/20, Step: 460/626, Loss: 0.3610\n","Iteration: 13/20, Step: 470/626, Loss: 0.6702\n","Iteration: 13/20, Step: 480/626, Loss: 0.4802\n","Iteration: 13/20, Step: 490/626, Loss: 0.4168\n","Iteration: 13/20, Step: 500/626, Loss: 0.4534\n","Iteration: 13/20, Step: 510/626, Loss: 0.5632\n","Iteration: 13/20, Step: 520/626, Loss: 0.5368\n","Iteration: 13/20, Step: 530/626, Loss: 0.4896\n","Iteration: 13/20, Step: 540/626, Loss: 0.6191\n","Iteration: 13/20, Step: 550/626, Loss: 0.4935\n","Iteration: 13/20, Step: 560/626, Loss: 0.5083\n","Iteration: 13/20, Step: 570/626, Loss: 0.5920\n","Iteration: 13/20, Step: 580/626, Loss: 0.5132\n","Iteration: 13/20, Step: 590/626, Loss: 0.5953\n","Iteration: 13/20, Step: 600/626, Loss: 0.3825\n","Iteration: 13/20, Step: 610/626, Loss: 0.7341\n","Iteration: 13/20, Step: 620/626, Loss: 0.6663\n","Iteration: 13/20, Test accuracy: 74.2857\n","Iteration: 14/20, Step: 10/626, Loss: 0.3740\n","Iteration: 14/20, Step: 20/626, Loss: 0.5711\n","Iteration: 14/20, Step: 30/626, Loss: 0.2105\n","Iteration: 14/20, Step: 40/626, Loss: 0.2825\n","Iteration: 14/20, Step: 50/626, Loss: 0.3267\n","Iteration: 14/20, Step: 60/626, Loss: 0.3848\n","Iteration: 14/20, Step: 70/626, Loss: 0.4634\n","Iteration: 14/20, Step: 80/626, Loss: 0.2731\n","Iteration: 14/20, Step: 90/626, Loss: 0.2310\n","Iteration: 14/20, Step: 100/626, Loss: 0.2673\n","Iteration: 14/20, Step: 110/626, Loss: 0.5973\n","Iteration: 14/20, Step: 120/626, Loss: 0.7398\n","Iteration: 14/20, Step: 130/626, Loss: 0.9835\n","Iteration: 14/20, Step: 140/626, Loss: 0.2721\n","Iteration: 14/20, Step: 150/626, Loss: 0.6502\n","Iteration: 14/20, Step: 160/626, Loss: 0.5713\n","Iteration: 14/20, Step: 170/626, Loss: 0.6008\n","Iteration: 14/20, Step: 180/626, Loss: 0.5094\n","Iteration: 14/20, Step: 190/626, Loss: 0.6076\n","Iteration: 14/20, Step: 200/626, Loss: 0.4467\n","Iteration: 14/20, Step: 210/626, Loss: 0.4127\n","Iteration: 14/20, Step: 220/626, Loss: 0.6254\n","Iteration: 14/20, Step: 230/626, Loss: 0.4577\n","Iteration: 14/20, Step: 240/626, Loss: 0.3311\n","Iteration: 14/20, Step: 250/626, Loss: 0.4618\n","Iteration: 14/20, Step: 260/626, Loss: 0.3817\n","Iteration: 14/20, Step: 270/626, Loss: 0.2620\n","Iteration: 14/20, Step: 280/626, Loss: 0.3574\n","Iteration: 14/20, Step: 290/626, Loss: 0.5001\n","Iteration: 14/20, Step: 300/626, Loss: 0.3000\n","Iteration: 14/20, Step: 310/626, Loss: 0.4592\n","Iteration: 14/20, Step: 320/626, Loss: 0.6425\n","Iteration: 14/20, Step: 330/626, Loss: 0.3691\n","Iteration: 14/20, Step: 340/626, Loss: 0.4626\n","Iteration: 14/20, Step: 350/626, Loss: 0.2585\n","Iteration: 14/20, Step: 360/626, Loss: 0.5635\n","Iteration: 14/20, Step: 370/626, Loss: 0.3060\n","Iteration: 14/20, Step: 380/626, Loss: 0.5455\n","Iteration: 14/20, Step: 390/626, Loss: 0.6993\n","Iteration: 14/20, Step: 400/626, Loss: 0.5240\n","Iteration: 14/20, Step: 410/626, Loss: 0.5624\n","Iteration: 14/20, Step: 420/626, Loss: 0.2971\n","Iteration: 14/20, Step: 430/626, Loss: 0.3607\n","Iteration: 14/20, Step: 440/626, Loss: 1.1402\n","Iteration: 14/20, Step: 450/626, Loss: 0.4248\n","Iteration: 14/20, Step: 460/626, Loss: 0.4834\n","Iteration: 14/20, Step: 470/626, Loss: 0.5391\n","Iteration: 14/20, Step: 480/626, Loss: 0.5185\n","Iteration: 14/20, Step: 490/626, Loss: 0.5567\n","Iteration: 14/20, Step: 500/626, Loss: 0.1763\n","Iteration: 14/20, Step: 510/626, Loss: 0.7031\n","Iteration: 14/20, Step: 520/626, Loss: 0.4926\n","Iteration: 14/20, Step: 530/626, Loss: 0.3959\n","Iteration: 14/20, Step: 540/626, Loss: 0.2933\n","Iteration: 14/20, Step: 550/626, Loss: 0.3445\n","Iteration: 14/20, Step: 560/626, Loss: 0.3339\n","Iteration: 14/20, Step: 570/626, Loss: 0.4064\n","Iteration: 14/20, Step: 580/626, Loss: 0.5579\n","Iteration: 14/20, Step: 590/626, Loss: 0.3237\n","Iteration: 14/20, Step: 600/626, Loss: 0.5532\n","Iteration: 14/20, Step: 610/626, Loss: 0.4681\n","Iteration: 14/20, Step: 620/626, Loss: 0.2932\n","Iteration: 14/20, Test accuracy: 75.4762\n","Iteration: 15/20, Step: 10/626, Loss: 0.3228\n","Iteration: 15/20, Step: 20/626, Loss: 0.3916\n","Iteration: 15/20, Step: 30/626, Loss: 0.4340\n","Iteration: 15/20, Step: 40/626, Loss: 0.5579\n","Iteration: 15/20, Step: 50/626, Loss: 0.3299\n","Iteration: 15/20, Step: 60/626, Loss: 0.2963\n","Iteration: 15/20, Step: 70/626, Loss: 0.4349\n","Iteration: 15/20, Step: 80/626, Loss: 0.3796\n","Iteration: 15/20, Step: 90/626, Loss: 0.5596\n","Iteration: 15/20, Step: 100/626, Loss: 0.5404\n","Iteration: 15/20, Step: 110/626, Loss: 0.7316\n","Iteration: 15/20, Step: 120/626, Loss: 0.5359\n","Iteration: 15/20, Step: 130/626, Loss: 0.3343\n","Iteration: 15/20, Step: 140/626, Loss: 0.4783\n","Iteration: 15/20, Step: 150/626, Loss: 0.4268\n","Iteration: 15/20, Step: 160/626, Loss: 0.3341\n","Iteration: 15/20, Step: 170/626, Loss: 0.3880\n","Iteration: 15/20, Step: 180/626, Loss: 0.2447\n","Iteration: 15/20, Step: 190/626, Loss: 0.3607\n","Iteration: 15/20, Step: 200/626, Loss: 0.3248\n","Iteration: 15/20, Step: 210/626, Loss: 0.6056\n","Iteration: 15/20, Step: 220/626, Loss: 0.2707\n","Iteration: 15/20, Step: 230/626, Loss: 0.2459\n","Iteration: 15/20, Step: 240/626, Loss: 0.2405\n","Iteration: 15/20, Step: 250/626, Loss: 0.5424\n","Iteration: 15/20, Step: 260/626, Loss: 0.2074\n","Iteration: 15/20, Step: 270/626, Loss: 0.3474\n","Iteration: 15/20, Step: 280/626, Loss: 0.1819\n","Iteration: 15/20, Step: 290/626, Loss: 0.3713\n","Iteration: 15/20, Step: 300/626, Loss: 0.2827\n","Iteration: 15/20, Step: 310/626, Loss: 0.3542\n","Iteration: 15/20, Step: 320/626, Loss: 0.3755\n","Iteration: 15/20, Step: 330/626, Loss: 0.3566\n","Iteration: 15/20, Step: 340/626, Loss: 0.1607\n","Iteration: 15/20, Step: 350/626, Loss: 0.4108\n","Iteration: 15/20, Step: 360/626, Loss: 0.2141\n","Iteration: 15/20, Step: 370/626, Loss: 0.2389\n","Iteration: 15/20, Step: 380/626, Loss: 0.5764\n","Iteration: 15/20, Step: 390/626, Loss: 0.4977\n","Iteration: 15/20, Step: 400/626, Loss: 0.7227\n","Iteration: 15/20, Step: 410/626, Loss: 0.4244\n","Iteration: 15/20, Step: 420/626, Loss: 0.2701\n","Iteration: 15/20, Step: 430/626, Loss: 0.3608\n","Iteration: 15/20, Step: 440/626, Loss: 0.2636\n","Iteration: 15/20, Step: 450/626, Loss: 0.6422\n","Iteration: 15/20, Step: 460/626, Loss: 0.3551\n","Iteration: 15/20, Step: 470/626, Loss: 0.3658\n","Iteration: 15/20, Step: 480/626, Loss: 0.6132\n","Iteration: 15/20, Step: 490/626, Loss: 0.5830\n","Iteration: 15/20, Step: 500/626, Loss: 0.2548\n","Iteration: 15/20, Step: 510/626, Loss: 0.8875\n","Iteration: 15/20, Step: 520/626, Loss: 0.2918\n","Iteration: 15/20, Step: 530/626, Loss: 0.5835\n","Iteration: 15/20, Step: 540/626, Loss: 0.3126\n","Iteration: 15/20, Step: 550/626, Loss: 0.5194\n","Iteration: 15/20, Step: 560/626, Loss: 0.4069\n","Iteration: 15/20, Step: 570/626, Loss: 0.5001\n","Iteration: 15/20, Step: 580/626, Loss: 0.7128\n","Iteration: 15/20, Step: 590/626, Loss: 0.5924\n","Iteration: 15/20, Step: 600/626, Loss: 0.2929\n","Iteration: 15/20, Step: 610/626, Loss: 0.3742\n","Iteration: 15/20, Step: 620/626, Loss: 0.5245\n","Iteration: 15/20, Test accuracy: 75.7619\n","Iteration: 16/20, Step: 10/626, Loss: 0.3839\n","Iteration: 16/20, Step: 20/626, Loss: 0.2754\n","Iteration: 16/20, Step: 30/626, Loss: 0.6026\n","Iteration: 16/20, Step: 40/626, Loss: 0.2275\n","Iteration: 16/20, Step: 50/626, Loss: 0.3781\n","Iteration: 16/20, Step: 60/626, Loss: 0.5729\n","Iteration: 16/20, Step: 70/626, Loss: 0.4473\n","Iteration: 16/20, Step: 80/626, Loss: 0.2940\n","Iteration: 16/20, Step: 90/626, Loss: 0.5103\n","Iteration: 16/20, Step: 100/626, Loss: 0.4744\n","Iteration: 16/20, Step: 110/626, Loss: 0.5536\n","Iteration: 16/20, Step: 120/626, Loss: 0.2890\n","Iteration: 16/20, Step: 130/626, Loss: 0.2729\n","Iteration: 16/20, Step: 140/626, Loss: 0.3465\n","Iteration: 16/20, Step: 150/626, Loss: 0.4001\n","Iteration: 16/20, Step: 160/626, Loss: 0.2427\n","Iteration: 16/20, Step: 170/626, Loss: 0.2741\n","Iteration: 16/20, Step: 180/626, Loss: 0.4187\n","Iteration: 16/20, Step: 190/626, Loss: 0.4590\n","Iteration: 16/20, Step: 200/626, Loss: 0.4472\n","Iteration: 16/20, Step: 210/626, Loss: 0.3473\n","Iteration: 16/20, Step: 220/626, Loss: 0.4372\n","Iteration: 16/20, Step: 230/626, Loss: 0.4146\n","Iteration: 16/20, Step: 240/626, Loss: 0.6223\n","Iteration: 16/20, Step: 250/626, Loss: 0.3106\n","Iteration: 16/20, Step: 260/626, Loss: 0.7642\n","Iteration: 16/20, Step: 270/626, Loss: 0.3709\n","Iteration: 16/20, Step: 280/626, Loss: 0.3572\n","Iteration: 16/20, Step: 290/626, Loss: 0.2129\n","Iteration: 16/20, Step: 300/626, Loss: 0.2821\n","Iteration: 16/20, Step: 310/626, Loss: 0.2909\n","Iteration: 16/20, Step: 320/626, Loss: 0.3947\n","Iteration: 16/20, Step: 330/626, Loss: 0.4417\n","Iteration: 16/20, Step: 340/626, Loss: 0.4999\n","Iteration: 16/20, Step: 350/626, Loss: 0.5326\n","Iteration: 16/20, Step: 360/626, Loss: 0.4301\n","Iteration: 16/20, Step: 370/626, Loss: 0.4646\n","Iteration: 16/20, Step: 380/626, Loss: 0.3399\n","Iteration: 16/20, Step: 390/626, Loss: 0.5209\n","Iteration: 16/20, Step: 400/626, Loss: 0.7453\n","Iteration: 16/20, Step: 410/626, Loss: 0.2779\n","Iteration: 16/20, Step: 420/626, Loss: 0.2373\n","Iteration: 16/20, Step: 430/626, Loss: 0.3842\n","Iteration: 16/20, Step: 440/626, Loss: 0.2172\n","Iteration: 16/20, Step: 450/626, Loss: 0.5249\n","Iteration: 16/20, Step: 460/626, Loss: 0.3065\n","Iteration: 16/20, Step: 470/626, Loss: 0.4460\n","Iteration: 16/20, Step: 480/626, Loss: 0.3716\n","Iteration: 16/20, Step: 490/626, Loss: 0.9397\n","Iteration: 16/20, Step: 500/626, Loss: 0.3797\n","Iteration: 16/20, Step: 510/626, Loss: 0.3903\n","Iteration: 16/20, Step: 520/626, Loss: 0.4204\n","Iteration: 16/20, Step: 530/626, Loss: 0.4688\n","Iteration: 16/20, Step: 540/626, Loss: 0.4881\n","Iteration: 16/20, Step: 550/626, Loss: 0.2890\n","Iteration: 16/20, Step: 560/626, Loss: 0.3722\n","Iteration: 16/20, Step: 570/626, Loss: 0.2017\n","Iteration: 16/20, Step: 580/626, Loss: 0.3206\n","Iteration: 16/20, Step: 590/626, Loss: 0.2480\n","Iteration: 16/20, Step: 600/626, Loss: 0.2927\n","Iteration: 16/20, Step: 610/626, Loss: 0.4391\n","Iteration: 16/20, Step: 620/626, Loss: 0.2256\n","Iteration: 16/20, Test accuracy: 75.0952\n","Iteration: 17/20, Step: 10/626, Loss: 0.4503\n","Iteration: 17/20, Step: 20/626, Loss: 0.2497\n","Iteration: 17/20, Step: 30/626, Loss: 0.3158\n","Iteration: 17/20, Step: 40/626, Loss: 0.2481\n","Iteration: 17/20, Step: 50/626, Loss: 0.3966\n","Iteration: 17/20, Step: 60/626, Loss: 0.1887\n","Iteration: 17/20, Step: 70/626, Loss: 0.3501\n","Iteration: 17/20, Step: 80/626, Loss: 0.4922\n","Iteration: 17/20, Step: 90/626, Loss: 0.1935\n","Iteration: 17/20, Step: 100/626, Loss: 0.2844\n","Iteration: 17/20, Step: 110/626, Loss: 0.5931\n","Iteration: 17/20, Step: 120/626, Loss: 0.3752\n","Iteration: 17/20, Step: 130/626, Loss: 0.2729\n","Iteration: 17/20, Step: 140/626, Loss: 0.3583\n","Iteration: 17/20, Step: 150/626, Loss: 0.3382\n","Iteration: 17/20, Step: 160/626, Loss: 0.2208\n","Iteration: 17/20, Step: 170/626, Loss: 0.2697\n","Iteration: 17/20, Step: 180/626, Loss: 0.7339\n","Iteration: 17/20, Step: 190/626, Loss: 0.4114\n","Iteration: 17/20, Step: 200/626, Loss: 0.3271\n","Iteration: 17/20, Step: 210/626, Loss: 0.2171\n","Iteration: 17/20, Step: 220/626, Loss: 0.4459\n","Iteration: 17/20, Step: 230/626, Loss: 0.4045\n","Iteration: 17/20, Step: 240/626, Loss: 0.2719\n","Iteration: 17/20, Step: 250/626, Loss: 0.4578\n","Iteration: 17/20, Step: 260/626, Loss: 0.6202\n","Iteration: 17/20, Step: 270/626, Loss: 0.3213\n","Iteration: 17/20, Step: 280/626, Loss: 0.3028\n","Iteration: 17/20, Step: 290/626, Loss: 0.3336\n","Iteration: 17/20, Step: 300/626, Loss: 0.4249\n","Iteration: 17/20, Step: 310/626, Loss: 0.3034\n","Iteration: 17/20, Step: 320/626, Loss: 0.2038\n","Iteration: 17/20, Step: 330/626, Loss: 0.3473\n","Iteration: 17/20, Step: 340/626, Loss: 0.3160\n","Iteration: 17/20, Step: 350/626, Loss: 0.3887\n","Iteration: 17/20, Step: 360/626, Loss: 0.3327\n","Iteration: 17/20, Step: 370/626, Loss: 0.4559\n","Iteration: 17/20, Step: 380/626, Loss: 0.3582\n","Iteration: 17/20, Step: 390/626, Loss: 0.4095\n","Iteration: 17/20, Step: 400/626, Loss: 0.5901\n","Iteration: 17/20, Step: 410/626, Loss: 0.5520\n","Iteration: 17/20, Step: 420/626, Loss: 0.3416\n","Iteration: 17/20, Step: 430/626, Loss: 0.3435\n","Iteration: 17/20, Step: 440/626, Loss: 0.3916\n","Iteration: 17/20, Step: 450/626, Loss: 0.6066\n","Iteration: 17/20, Step: 460/626, Loss: 0.5395\n","Iteration: 17/20, Step: 470/626, Loss: 0.3304\n","Iteration: 17/20, Step: 480/626, Loss: 0.3053\n","Iteration: 17/20, Step: 490/626, Loss: 0.2536\n","Iteration: 17/20, Step: 500/626, Loss: 0.5552\n","Iteration: 17/20, Step: 510/626, Loss: 0.3630\n","Iteration: 17/20, Step: 520/626, Loss: 0.3764\n","Iteration: 17/20, Step: 530/626, Loss: 0.5094\n","Iteration: 17/20, Step: 540/626, Loss: 0.3650\n","Iteration: 17/20, Step: 550/626, Loss: 0.4501\n","Iteration: 17/20, Step: 560/626, Loss: 0.2197\n","Iteration: 17/20, Step: 570/626, Loss: 0.3865\n","Iteration: 17/20, Step: 580/626, Loss: 0.3325\n","Iteration: 17/20, Step: 590/626, Loss: 0.8689\n","Iteration: 17/20, Step: 600/626, Loss: 0.2757\n","Iteration: 17/20, Step: 610/626, Loss: 0.5197\n","Iteration: 17/20, Step: 620/626, Loss: 0.1701\n","Iteration: 17/20, Test accuracy: 77.0000\n","Iteration: 18/20, Step: 10/626, Loss: 0.1772\n","Iteration: 18/20, Step: 20/626, Loss: 0.3689\n","Iteration: 18/20, Step: 30/626, Loss: 0.5863\n","Iteration: 18/20, Step: 40/626, Loss: 0.4322\n","Iteration: 18/20, Step: 50/626, Loss: 0.3766\n","Iteration: 18/20, Step: 60/626, Loss: 0.3273\n","Iteration: 18/20, Step: 70/626, Loss: 0.2424\n","Iteration: 18/20, Step: 80/626, Loss: 0.3792\n","Iteration: 18/20, Step: 90/626, Loss: 0.4697\n","Iteration: 18/20, Step: 100/626, Loss: 0.3419\n","Iteration: 18/20, Step: 110/626, Loss: 0.4804\n","Iteration: 18/20, Step: 120/626, Loss: 0.2408\n","Iteration: 18/20, Step: 130/626, Loss: 0.5316\n","Iteration: 18/20, Step: 140/626, Loss: 0.1315\n","Iteration: 18/20, Step: 150/626, Loss: 0.3979\n","Iteration: 18/20, Step: 160/626, Loss: 0.3418\n","Iteration: 18/20, Step: 170/626, Loss: 0.1022\n","Iteration: 18/20, Step: 180/626, Loss: 0.2425\n","Iteration: 18/20, Step: 190/626, Loss: 0.3202\n","Iteration: 18/20, Step: 200/626, Loss: 0.6518\n","Iteration: 18/20, Step: 210/626, Loss: 0.4592\n","Iteration: 18/20, Step: 220/626, Loss: 0.4598\n","Iteration: 18/20, Step: 230/626, Loss: 0.5014\n","Iteration: 18/20, Step: 240/626, Loss: 0.4355\n","Iteration: 18/20, Step: 250/626, Loss: 0.2905\n","Iteration: 18/20, Step: 260/626, Loss: 0.4731\n","Iteration: 18/20, Step: 270/626, Loss: 0.2402\n","Iteration: 18/20, Step: 280/626, Loss: 0.4222\n","Iteration: 18/20, Step: 290/626, Loss: 0.3545\n","Iteration: 18/20, Step: 300/626, Loss: 0.4238\n","Iteration: 18/20, Step: 310/626, Loss: 0.3598\n","Iteration: 18/20, Step: 320/626, Loss: 0.3897\n","Iteration: 18/20, Step: 330/626, Loss: 0.3863\n","Iteration: 18/20, Step: 340/626, Loss: 0.4627\n","Iteration: 18/20, Step: 350/626, Loss: 0.3151\n","Iteration: 18/20, Step: 360/626, Loss: 0.1881\n","Iteration: 18/20, Step: 370/626, Loss: 0.3133\n","Iteration: 18/20, Step: 380/626, Loss: 0.4013\n","Iteration: 18/20, Step: 390/626, Loss: 0.4635\n","Iteration: 18/20, Step: 400/626, Loss: 0.3299\n","Iteration: 18/20, Step: 410/626, Loss: 0.2808\n","Iteration: 18/20, Step: 420/626, Loss: 0.2584\n","Iteration: 18/20, Step: 430/626, Loss: 0.4072\n","Iteration: 18/20, Step: 440/626, Loss: 0.3556\n","Iteration: 18/20, Step: 450/626, Loss: 0.5456\n","Iteration: 18/20, Step: 460/626, Loss: 0.3062\n","Iteration: 18/20, Step: 470/626, Loss: 0.3671\n","Iteration: 18/20, Step: 480/626, Loss: 0.3253\n","Iteration: 18/20, Step: 490/626, Loss: 0.3247\n","Iteration: 18/20, Step: 500/626, Loss: 0.3982\n","Iteration: 18/20, Step: 510/626, Loss: 0.4154\n","Iteration: 18/20, Step: 520/626, Loss: 0.5733\n","Iteration: 18/20, Step: 530/626, Loss: 0.3071\n","Iteration: 18/20, Step: 540/626, Loss: 0.2714\n","Iteration: 18/20, Step: 550/626, Loss: 0.3838\n","Iteration: 18/20, Step: 560/626, Loss: 0.2862\n","Iteration: 18/20, Step: 570/626, Loss: 0.3951\n","Iteration: 18/20, Step: 580/626, Loss: 0.2499\n","Iteration: 18/20, Step: 590/626, Loss: 0.3105\n","Iteration: 18/20, Step: 600/626, Loss: 0.6611\n","Iteration: 18/20, Step: 610/626, Loss: 0.3256\n","Iteration: 18/20, Step: 620/626, Loss: 0.2664\n","Iteration: 18/20, Test accuracy: 77.3810\n","Iteration: 19/20, Step: 10/626, Loss: 0.1707\n","Iteration: 19/20, Step: 20/626, Loss: 0.3653\n","Iteration: 19/20, Step: 30/626, Loss: 0.2367\n","Iteration: 19/20, Step: 40/626, Loss: 0.5252\n","Iteration: 19/20, Step: 50/626, Loss: 0.1492\n","Iteration: 19/20, Step: 60/626, Loss: 0.4874\n","Iteration: 19/20, Step: 70/626, Loss: 0.3121\n","Iteration: 19/20, Step: 80/626, Loss: 0.4008\n","Iteration: 19/20, Step: 90/626, Loss: 0.1669\n","Iteration: 19/20, Step: 100/626, Loss: 0.1074\n","Iteration: 19/20, Step: 110/626, Loss: 0.3693\n","Iteration: 19/20, Step: 120/626, Loss: 0.4323\n","Iteration: 19/20, Step: 130/626, Loss: 0.1171\n","Iteration: 19/20, Step: 140/626, Loss: 0.4407\n","Iteration: 19/20, Step: 150/626, Loss: 0.5106\n","Iteration: 19/20, Step: 160/626, Loss: 0.2445\n","Iteration: 19/20, Step: 170/626, Loss: 0.4317\n","Iteration: 19/20, Step: 180/626, Loss: 0.4402\n","Iteration: 19/20, Step: 190/626, Loss: 0.6314\n","Iteration: 19/20, Step: 200/626, Loss: 0.2961\n","Iteration: 19/20, Step: 210/626, Loss: 0.2955\n","Iteration: 19/20, Step: 220/626, Loss: 0.4289\n","Iteration: 19/20, Step: 230/626, Loss: 0.3223\n","Iteration: 19/20, Step: 240/626, Loss: 0.4029\n","Iteration: 19/20, Step: 250/626, Loss: 0.2760\n","Iteration: 19/20, Step: 260/626, Loss: 0.2334\n","Iteration: 19/20, Step: 270/626, Loss: 0.4170\n","Iteration: 19/20, Step: 280/626, Loss: 0.2135\n","Iteration: 19/20, Step: 290/626, Loss: 0.6703\n","Iteration: 19/20, Step: 300/626, Loss: 0.3535\n","Iteration: 19/20, Step: 310/626, Loss: 0.3963\n","Iteration: 19/20, Step: 320/626, Loss: 0.5592\n","Iteration: 19/20, Step: 330/626, Loss: 0.3223\n","Iteration: 19/20, Step: 340/626, Loss: 0.4815\n","Iteration: 19/20, Step: 350/626, Loss: 0.3462\n","Iteration: 19/20, Step: 360/626, Loss: 0.2209\n","Iteration: 19/20, Step: 370/626, Loss: 0.1521\n","Iteration: 19/20, Step: 380/626, Loss: 0.6574\n","Iteration: 19/20, Step: 390/626, Loss: 0.3173\n","Iteration: 19/20, Step: 400/626, Loss: 0.1173\n","Iteration: 19/20, Step: 410/626, Loss: 0.1679\n","Iteration: 19/20, Step: 420/626, Loss: 0.5299\n","Iteration: 19/20, Step: 430/626, Loss: 0.3884\n","Iteration: 19/20, Step: 440/626, Loss: 0.3721\n","Iteration: 19/20, Step: 450/626, Loss: 0.6235\n","Iteration: 19/20, Step: 460/626, Loss: 0.5228\n","Iteration: 19/20, Step: 470/626, Loss: 0.4143\n","Iteration: 19/20, Step: 480/626, Loss: 0.1825\n","Iteration: 19/20, Step: 490/626, Loss: 0.1910\n","Iteration: 19/20, Step: 500/626, Loss: 0.3302\n","Iteration: 19/20, Step: 510/626, Loss: 0.5471\n","Iteration: 19/20, Step: 520/626, Loss: 0.2896\n","Iteration: 19/20, Step: 530/626, Loss: 0.4945\n","Iteration: 19/20, Step: 540/626, Loss: 0.2640\n","Iteration: 19/20, Step: 550/626, Loss: 0.4658\n","Iteration: 19/20, Step: 560/626, Loss: 0.3833\n","Iteration: 19/20, Step: 570/626, Loss: 0.4673\n","Iteration: 19/20, Step: 580/626, Loss: 0.5447\n","Iteration: 19/20, Step: 590/626, Loss: 0.3072\n","Iteration: 19/20, Step: 600/626, Loss: 0.3576\n","Iteration: 19/20, Step: 610/626, Loss: 0.3143\n","Iteration: 19/20, Step: 620/626, Loss: 0.3344\n","Iteration: 19/20, Test accuracy: 77.6190\n","Iteration: 20/20, Step: 10/626, Loss: 0.2866\n","Iteration: 20/20, Step: 20/626, Loss: 0.2831\n","Iteration: 20/20, Step: 30/626, Loss: 0.2687\n","Iteration: 20/20, Step: 40/626, Loss: 0.2532\n","Iteration: 20/20, Step: 50/626, Loss: 0.4183\n","Iteration: 20/20, Step: 60/626, Loss: 0.5304\n","Iteration: 20/20, Step: 70/626, Loss: 0.2210\n","Iteration: 20/20, Step: 80/626, Loss: 0.3904\n","Iteration: 20/20, Step: 90/626, Loss: 0.3584\n","Iteration: 20/20, Step: 100/626, Loss: 0.1440\n","Iteration: 20/20, Step: 110/626, Loss: 0.4660\n","Iteration: 20/20, Step: 120/626, Loss: 0.2969\n","Iteration: 20/20, Step: 130/626, Loss: 0.2089\n","Iteration: 20/20, Step: 140/626, Loss: 0.3559\n","Iteration: 20/20, Step: 150/626, Loss: 0.3045\n","Iteration: 20/20, Step: 160/626, Loss: 0.3912\n","Iteration: 20/20, Step: 170/626, Loss: 0.1748\n","Iteration: 20/20, Step: 180/626, Loss: 0.1953\n","Iteration: 20/20, Step: 190/626, Loss: 0.4132\n","Iteration: 20/20, Step: 200/626, Loss: 0.3231\n","Iteration: 20/20, Step: 210/626, Loss: 0.4888\n","Iteration: 20/20, Step: 220/626, Loss: 0.3143\n","Iteration: 20/20, Step: 230/626, Loss: 0.2512\n","Iteration: 20/20, Step: 240/626, Loss: 0.2255\n","Iteration: 20/20, Step: 250/626, Loss: 0.4213\n","Iteration: 20/20, Step: 260/626, Loss: 0.3051\n","Iteration: 20/20, Step: 270/626, Loss: 0.3254\n","Iteration: 20/20, Step: 280/626, Loss: 0.2237\n","Iteration: 20/20, Step: 290/626, Loss: 0.1156\n","Iteration: 20/20, Step: 300/626, Loss: 0.2239\n","Iteration: 20/20, Step: 310/626, Loss: 0.4912\n","Iteration: 20/20, Step: 320/626, Loss: 0.1881\n","Iteration: 20/20, Step: 330/626, Loss: 0.4377\n","Iteration: 20/20, Step: 340/626, Loss: 0.3380\n","Iteration: 20/20, Step: 350/626, Loss: 0.3371\n","Iteration: 20/20, Step: 360/626, Loss: 0.2812\n","Iteration: 20/20, Step: 370/626, Loss: 0.2988\n","Iteration: 20/20, Step: 380/626, Loss: 0.3634\n","Iteration: 20/20, Step: 390/626, Loss: 0.2138\n","Iteration: 20/20, Step: 400/626, Loss: 0.3103\n","Iteration: 20/20, Step: 410/626, Loss: 0.4138\n","Iteration: 20/20, Step: 420/626, Loss: 0.3960\n","Iteration: 20/20, Step: 430/626, Loss: 0.2725\n","Iteration: 20/20, Step: 440/626, Loss: 0.4720\n","Iteration: 20/20, Step: 450/626, Loss: 0.2462\n","Iteration: 20/20, Step: 460/626, Loss: 0.3044\n","Iteration: 20/20, Step: 470/626, Loss: 0.4182\n","Iteration: 20/20, Step: 480/626, Loss: 0.4039\n","Iteration: 20/20, Step: 490/626, Loss: 0.4091\n","Iteration: 20/20, Step: 500/626, Loss: 0.3940\n","Iteration: 20/20, Step: 510/626, Loss: 0.2088\n","Iteration: 20/20, Step: 520/626, Loss: 0.2306\n","Iteration: 20/20, Step: 530/626, Loss: 0.4492\n","Iteration: 20/20, Step: 540/626, Loss: 0.3585\n","Iteration: 20/20, Step: 550/626, Loss: 0.5054\n","Iteration: 20/20, Step: 560/626, Loss: 0.3419\n","Iteration: 20/20, Step: 570/626, Loss: 0.1817\n","Iteration: 20/20, Step: 580/626, Loss: 0.2178\n","Iteration: 20/20, Step: 590/626, Loss: 0.5032\n","Iteration: 20/20, Step: 600/626, Loss: 0.1940\n","Iteration: 20/20, Step: 610/626, Loss: 0.1818\n","Iteration: 20/20, Step: 620/626, Loss: 0.3364\n","Iteration: 20/20, Test accuracy: 76.5238\n","Best test accuracy: 77.6190\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","n_epochs = 20\n","lr = 0.001\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n","loss_func = torch.nn.CrossEntropyLoss()\n","best_test_acc = 0\n","\n","for i in range(n_epochs):\n","    for idx, (image, label) in enumerate(train_loader):\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        y_pred = model(image)[0]\n","        loss = loss_func(y_pred, label)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (idx + 1) % 10 == 0:\n","            print(f'Iteration: {i+1}/{n_epochs}, Step: {idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        n_instances = len(test_loader)\n","        n_correct = 0\n","        for image, label in test_loader:\n","            image = image.to(device)\n","            label = label.to(device)\n","            \n","            y_pred = model(image)\n","            pred = torch.argmax(y_pred, dim=1)\n","            n_correct += (pred == label).sum().item()\n","        test_acc = n_correct / n_instances\n","        print(f'Iteration: {i+1}/{n_epochs}, Test accuracy: {test_acc:.4f}')\n","        \n","        if test_acc > best_test_acc:\n","            best_test_acc = test_acc\n","            torch.save(model, 'best_model.pth')\n","        \n","    model.train()\n","    \n","print(f'Best test accuracy: {best_test_acc:.4f}')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"xoB_kHvt8uSL","executionInfo":{"status":"ok","timestamp":1667811338771,"user_tz":-480,"elapsed":3890,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"outputs":[],"source":["!cp /content/best_model.pth /content/drive/MyDrive"]},{"cell_type":"markdown","source":["# 5. Evaluate"],"metadata":{"id":"D3vtat6V4PRz"}},{"cell_type":"code","source":["best_model = torch.load('best_model.pth')\n","best_model.eval()\n","with torch.no_grad():\n","    y_preds = []\n","    y_trues = []\n","    for image, label in test_loader:\n","        image = image.to(device)\n","        label = label.to(device)\n","        \n","        y_pred = best_model(image)\n","        pred = torch.argmax(y_pred, dim=1)\n","\n","        y_trues.append(label.cpu().numpy())\n","        y_preds.append(pred.cpu().numpy())\n"],"metadata":{"id":"8ipKOZVhtpLR","executionInfo":{"status":"ok","timestamp":1667811370680,"user_tz":-480,"elapsed":31915,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import recall_score\n","\n","y_preds = np.concatenate(y_preds)\n","y_trues = np.concatenate(y_trues)\n","\n","scores = recall_score(y_trues, y_preds, average=None)\n","scores"],"metadata":{"id":"BXE46oNzALXp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667811370681,"user_tz":-480,"elapsed":28,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}},"outputId":"496d2a75-9d88-483b-fa18-16996c6e8b71"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.73333333, 0.65420561, 0.62616822, 0.74074074, 0.50218341,\n","       0.91465257, 0.88888889])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","test_acc = accuracy_score(y_trues, y_preds)\n","test_acc"],"metadata":{"id":"qO8iYlqv4tQW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667811370681,"user_tz":-480,"elapsed":15,"user":{"displayName":"小·白菜","userId":"11363145687516653892"}},"outputId":"0851176f-06ed-4c4f-b0ee-70fed4ed945d"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8132800798801797"]},"metadata":{},"execution_count":13}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}