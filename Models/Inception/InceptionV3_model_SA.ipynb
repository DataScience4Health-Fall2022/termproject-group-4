{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31191,
     "status": "ok",
     "timestamp": 1667711113138,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "NFXvgzy18_Zx",
    "outputId": "3f004f49-9fa5-4551-ff48-16e1df97688d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkMRUU1Y-uRY"
   },
   "outputs": [],
   "source": [
    "!unzip -d ./dataverse_files /content/drive/MyDrive/dataverse_files.zip\n",
    "\n",
    "!unzip -d ./dataverse_files/HAM10000_images_part_1 /content/dataverse_files/HAM10000_images_part_1.zip\n",
    "!unzip -d ./dataverse_files/HAM10000_images_part_2 /content/dataverse_files/HAM10000_images_part_2.zip\n",
    "!unzip -d ./dataverse_files /content/dataverse_files/ISIC2018_Task3_Test_Images.zip\n",
    "\n",
    "!unzip -d ./dataverse_files /content/drive/MyDrive/InceptionV3.zip\n",
    "\n",
    "!unzip -d ./dataverse_files /content/dataverse_files/GAN_Images-20221105T161540Z-001.zip\n",
    "!unzip -d ./dataverse_files /content/dataverse_files/HAM10000_images_augmented-20221103T160519Z-001.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXsRqaAw8uSC"
   },
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1667711206413,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "-9GMygDv9MXz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2940,
     "status": "ok",
     "timestamp": 1667711309294,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "c7Pq1JKY8uSE"
   },
   "outputs": [],
   "source": [
    "# move training images into folders\n",
    "\n",
    "# create train folder\n",
    "if not os.path.exists('dataverse_files/train'):\n",
    "    os.mkdir('dataverse_files/train')\n",
    "    \n",
    "for img_name in os.listdir('dataverse_files/HAM10000_images_part_1/'):\n",
    "    src_path = os.path.join('dataverse_files/HAM10000_images_part_1', img_name)\n",
    "    tgt_path = 'dataverse_files/train'\n",
    "    shutil.move(src_path, tgt_path)\n",
    "    \n",
    "for img_name in os.listdir('dataverse_files/HAM10000_images_part_2/'):\n",
    "    src_path = os.path.join('dataverse_files/HAM10000_images_part_2', img_name)\n",
    "    tgt_path = 'dataverse_files/train'\n",
    "    shutil.move(src_path, tgt_path)\n",
    "\n",
    "for img_name in os.listdir('dataverse_files/HAM10000_images_augmented/'):\n",
    "    src_path = os.path.join('dataverse_files/HAM10000_images_augmented', img_name)\n",
    "    renamed_src_path = os.path.join('dataverse_files/HAM10000_images_augmented', img_name.split('.')[0] + '_aug.jpg')\n",
    "    os.rename(src_path, renamed_src_path)\n",
    "    tgt_path = 'dataverse_files/train'\n",
    "    shutil.move(renamed_src_path, tgt_path)\n",
    "\n",
    "# for img_name in os.listdir('dataverse_files/GAN_Images/'):\n",
    "#     src_path = os.path.join('dataverse_files/GAN_Images', img_name)\n",
    "#     tgt_path = 'dataverse_files/train'\n",
    "#     shutil.move(src_path, tgt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2758,
     "status": "ok",
     "timestamp": 1667711364476,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "AanXRTN48uSF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df = pd.read_csv('dataverse_files/HAM10000_metadata')\n",
    "aug_train_df = pd.read_csv('dataverse_files/HAM10000_metadata_augmented.csv').iloc[:, 1:]\n",
    "aug_train_df['image_id'] = aug_train_df['image_id'].apply(lambda x: x+'_aug')\n",
    "\n",
    "# gan_df = pd.read_csv('dataverse_files/HAM10000_GAN_data.csv').iloc[:, 1:]\n",
    "\n",
    "train, test = train_test_split(train_df[['image_id', 'dx']], test_size=0.2)\n",
    "train = pd.concat((train, aug_train_df[['image_id', 'dx']]), axis=0)\n",
    "\n",
    "# gan_df['dx'] = gan_df['dx'].map({0: 'bkl', 1: 'nv', 2: 'df', 3: 'mel', 4: 'vasc', 5: 'bcc', 6: 'akiec'})\n",
    "# train = pd.concat((train, gan_df[['image_id', 'dx']]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1667711418691,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "WvoQ-GyK8uSF"
   },
   "outputs": [],
   "source": [
    "# convert to numerical representation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "lb.fit_transform(train_df['dx'])\n",
    "cls2lbl = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "lbl2cls = {idx: cls for idx, cls in enumerate(lb.classes_)}\n",
    "train['label'] = [cls2lbl[cls] for cls in train['dx']]\n",
    "test['label'] = [cls2lbl[cls] for cls in test['dx']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k84fTnEQ8uSH"
   },
   "source": [
    "# 2. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2976,
     "status": "ok",
     "timestamp": 1667711425130,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "rtcplVLc8uSI"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, RandomAffine, Resize, CenterCrop, Normalize\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        self.meta = train if mode == 'train' else test\n",
    "        self.root_dir = 'dataverse_files/train'\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.meta['image_id'].iloc[idx].startswith('GAN'):\n",
    "            img_name = self.meta['image_id'].iloc[idx]\n",
    "        else:\n",
    "            img_name = self.meta['image_id'].iloc[idx] + '.jpg'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = Resize((299, 299))(image)\n",
    "        image = RandomAffine(degrees=(-10, 10), translate=(0.05, 0.1), scale=(0.9, 1.1))(image)\n",
    "        image = ToTensor()(image)\n",
    "        image = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "        \n",
    "        label = self.meta['label'].iloc[idx]\n",
    "        return image, label\n",
    "\n",
    "train_dataset = MyDataset(mode='train')\n",
    "test_dataset = MyDataset(mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26caNCCK8uSJ"
   },
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1831,
     "status": "ok",
     "timestamp": 1667711455254,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "rkc2RY-v8uSJ",
    "outputId": "8325fac9-b249-4ec3-bbb8-9c5bdde38e5b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:47: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "model = inception_v3(pretrained=False)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 7))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk7cVHwN8uSK"
   },
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5661110,
     "status": "ok",
     "timestamp": 1667717122072,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "VJTD29ST8uSK",
    "outputId": "cbd4f328-1919-4656-aecf-31986e35f069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/15, Step: 10/439, Loss: 1.7450\n",
      "Iteration: 1/15, Step: 20/439, Loss: 1.5387\n",
      "Iteration: 1/15, Step: 30/439, Loss: 2.0450\n",
      "Iteration: 1/15, Step: 40/439, Loss: 1.3425\n",
      "Iteration: 1/15, Step: 50/439, Loss: 1.5700\n",
      "Iteration: 1/15, Step: 60/439, Loss: 1.7976\n",
      "Iteration: 1/15, Step: 70/439, Loss: 1.8631\n",
      "Iteration: 1/15, Step: 80/439, Loss: 1.0921\n",
      "Iteration: 1/15, Step: 90/439, Loss: 1.2671\n",
      "Iteration: 1/15, Step: 100/439, Loss: 1.3584\n",
      "Iteration: 1/15, Step: 110/439, Loss: 1.1344\n",
      "Iteration: 1/15, Step: 120/439, Loss: 1.7504\n",
      "Iteration: 1/15, Step: 130/439, Loss: 1.2113\n",
      "Iteration: 1/15, Step: 140/439, Loss: 1.2107\n",
      "Iteration: 1/15, Step: 150/439, Loss: 1.3459\n",
      "Iteration: 1/15, Step: 160/439, Loss: 1.2742\n",
      "Iteration: 1/15, Step: 170/439, Loss: 1.1761\n",
      "Iteration: 1/15, Step: 180/439, Loss: 1.4618\n",
      "Iteration: 1/15, Step: 190/439, Loss: 1.5091\n",
      "Iteration: 1/15, Step: 200/439, Loss: 1.2196\n",
      "Iteration: 1/15, Step: 210/439, Loss: 1.2484\n",
      "Iteration: 1/15, Step: 220/439, Loss: 1.1590\n",
      "Iteration: 1/15, Step: 230/439, Loss: 1.1454\n",
      "Iteration: 1/15, Step: 240/439, Loss: 1.2883\n",
      "Iteration: 1/15, Step: 250/439, Loss: 1.4223\n",
      "Iteration: 1/15, Step: 260/439, Loss: 1.1282\n",
      "Iteration: 1/15, Step: 270/439, Loss: 1.4726\n",
      "Iteration: 1/15, Step: 280/439, Loss: 1.0091\n",
      "Iteration: 1/15, Step: 290/439, Loss: 0.9975\n",
      "Iteration: 1/15, Step: 300/439, Loss: 1.3661\n",
      "Iteration: 1/15, Step: 310/439, Loss: 0.9823\n",
      "Iteration: 1/15, Step: 320/439, Loss: 1.1763\n",
      "Iteration: 1/15, Step: 330/439, Loss: 1.2508\n",
      "Iteration: 1/15, Step: 340/439, Loss: 1.4061\n",
      "Iteration: 1/15, Step: 350/439, Loss: 1.0015\n",
      "Iteration: 1/15, Step: 360/439, Loss: 1.1548\n",
      "Iteration: 1/15, Step: 370/439, Loss: 0.9764\n",
      "Iteration: 1/15, Step: 380/439, Loss: 1.1330\n",
      "Iteration: 1/15, Step: 390/439, Loss: 0.9994\n",
      "Iteration: 1/15, Step: 400/439, Loss: 1.0822\n",
      "Iteration: 1/15, Step: 410/439, Loss: 1.4442\n",
      "Iteration: 1/15, Step: 420/439, Loss: 0.9764\n",
      "Iteration: 1/15, Step: 430/439, Loss: 1.2058\n",
      "Iteration: 1/15, Test accuracy: 66.6667\n",
      "Iteration: 2/15, Step: 10/439, Loss: 1.2288\n",
      "Iteration: 2/15, Step: 20/439, Loss: 1.4743\n",
      "Iteration: 2/15, Step: 30/439, Loss: 1.0636\n",
      "Iteration: 2/15, Step: 40/439, Loss: 1.0541\n",
      "Iteration: 2/15, Step: 50/439, Loss: 1.1994\n",
      "Iteration: 2/15, Step: 60/439, Loss: 1.4422\n",
      "Iteration: 2/15, Step: 70/439, Loss: 0.9587\n",
      "Iteration: 2/15, Step: 80/439, Loss: 1.2148\n",
      "Iteration: 2/15, Step: 90/439, Loss: 1.2993\n",
      "Iteration: 2/15, Step: 100/439, Loss: 1.3005\n",
      "Iteration: 2/15, Step: 110/439, Loss: 1.0966\n",
      "Iteration: 2/15, Step: 120/439, Loss: 1.1997\n",
      "Iteration: 2/15, Step: 130/439, Loss: 1.0470\n",
      "Iteration: 2/15, Step: 140/439, Loss: 0.8763\n",
      "Iteration: 2/15, Step: 150/439, Loss: 1.5637\n",
      "Iteration: 2/15, Step: 160/439, Loss: 1.4135\n",
      "Iteration: 2/15, Step: 170/439, Loss: 1.2428\n",
      "Iteration: 2/15, Step: 180/439, Loss: 1.2422\n",
      "Iteration: 2/15, Step: 190/439, Loss: 0.8549\n",
      "Iteration: 2/15, Step: 200/439, Loss: 0.8410\n",
      "Iteration: 2/15, Step: 210/439, Loss: 0.9760\n",
      "Iteration: 2/15, Step: 220/439, Loss: 1.0682\n",
      "Iteration: 2/15, Step: 230/439, Loss: 1.0625\n",
      "Iteration: 2/15, Step: 240/439, Loss: 1.2698\n",
      "Iteration: 2/15, Step: 250/439, Loss: 1.4351\n",
      "Iteration: 2/15, Step: 260/439, Loss: 0.8242\n",
      "Iteration: 2/15, Step: 270/439, Loss: 1.0283\n",
      "Iteration: 2/15, Step: 280/439, Loss: 1.3172\n",
      "Iteration: 2/15, Step: 290/439, Loss: 1.1119\n",
      "Iteration: 2/15, Step: 300/439, Loss: 1.1765\n",
      "Iteration: 2/15, Step: 310/439, Loss: 1.1583\n",
      "Iteration: 2/15, Step: 320/439, Loss: 1.0773\n",
      "Iteration: 2/15, Step: 330/439, Loss: 0.7643\n",
      "Iteration: 2/15, Step: 340/439, Loss: 0.9059\n",
      "Iteration: 2/15, Step: 350/439, Loss: 0.9523\n",
      "Iteration: 2/15, Step: 360/439, Loss: 0.9101\n",
      "Iteration: 2/15, Step: 370/439, Loss: 1.2165\n",
      "Iteration: 2/15, Step: 380/439, Loss: 1.0945\n",
      "Iteration: 2/15, Step: 390/439, Loss: 0.8995\n",
      "Iteration: 2/15, Step: 400/439, Loss: 1.2812\n",
      "Iteration: 2/15, Step: 410/439, Loss: 0.8886\n",
      "Iteration: 2/15, Step: 420/439, Loss: 1.3175\n",
      "Iteration: 2/15, Step: 430/439, Loss: 0.8813\n",
      "Iteration: 2/15, Test accuracy: 66.4762\n",
      "Iteration: 3/15, Step: 10/439, Loss: 1.8877\n",
      "Iteration: 3/15, Step: 20/439, Loss: 0.9566\n",
      "Iteration: 3/15, Step: 30/439, Loss: 1.2609\n",
      "Iteration: 3/15, Step: 40/439, Loss: 1.2159\n",
      "Iteration: 3/15, Step: 50/439, Loss: 1.2157\n",
      "Iteration: 3/15, Step: 60/439, Loss: 1.2395\n",
      "Iteration: 3/15, Step: 70/439, Loss: 1.3067\n",
      "Iteration: 3/15, Step: 80/439, Loss: 1.1841\n",
      "Iteration: 3/15, Step: 90/439, Loss: 1.0348\n",
      "Iteration: 3/15, Step: 100/439, Loss: 1.0429\n",
      "Iteration: 3/15, Step: 110/439, Loss: 0.9179\n",
      "Iteration: 3/15, Step: 120/439, Loss: 1.4081\n",
      "Iteration: 3/15, Step: 130/439, Loss: 1.2471\n",
      "Iteration: 3/15, Step: 140/439, Loss: 0.9710\n",
      "Iteration: 3/15, Step: 150/439, Loss: 1.0131\n",
      "Iteration: 3/15, Step: 160/439, Loss: 1.2138\n",
      "Iteration: 3/15, Step: 170/439, Loss: 1.5063\n",
      "Iteration: 3/15, Step: 180/439, Loss: 1.1610\n",
      "Iteration: 3/15, Step: 190/439, Loss: 1.2066\n",
      "Iteration: 3/15, Step: 200/439, Loss: 0.8268\n",
      "Iteration: 3/15, Step: 210/439, Loss: 0.7969\n",
      "Iteration: 3/15, Step: 220/439, Loss: 1.3330\n",
      "Iteration: 3/15, Step: 230/439, Loss: 1.4421\n",
      "Iteration: 3/15, Step: 240/439, Loss: 1.4155\n",
      "Iteration: 3/15, Step: 250/439, Loss: 1.0285\n",
      "Iteration: 3/15, Step: 260/439, Loss: 1.0533\n",
      "Iteration: 3/15, Step: 270/439, Loss: 0.8123\n",
      "Iteration: 3/15, Step: 280/439, Loss: 1.0341\n",
      "Iteration: 3/15, Step: 290/439, Loss: 1.2677\n",
      "Iteration: 3/15, Step: 300/439, Loss: 1.2345\n",
      "Iteration: 3/15, Step: 310/439, Loss: 0.9257\n",
      "Iteration: 3/15, Step: 320/439, Loss: 0.9638\n",
      "Iteration: 3/15, Step: 330/439, Loss: 1.1235\n",
      "Iteration: 3/15, Step: 340/439, Loss: 1.2727\n",
      "Iteration: 3/15, Step: 350/439, Loss: 1.1569\n",
      "Iteration: 3/15, Step: 360/439, Loss: 0.8909\n",
      "Iteration: 3/15, Step: 370/439, Loss: 1.1305\n",
      "Iteration: 3/15, Step: 380/439, Loss: 1.0699\n",
      "Iteration: 3/15, Step: 390/439, Loss: 1.1086\n",
      "Iteration: 3/15, Step: 400/439, Loss: 1.0727\n",
      "Iteration: 3/15, Step: 410/439, Loss: 1.1494\n",
      "Iteration: 3/15, Step: 420/439, Loss: 1.0506\n",
      "Iteration: 3/15, Step: 430/439, Loss: 1.0163\n",
      "Iteration: 3/15, Test accuracy: 69.9048\n",
      "Iteration: 4/15, Step: 10/439, Loss: 1.1123\n",
      "Iteration: 4/15, Step: 20/439, Loss: 1.0035\n",
      "Iteration: 4/15, Step: 30/439, Loss: 1.0610\n",
      "Iteration: 4/15, Step: 40/439, Loss: 1.0779\n",
      "Iteration: 4/15, Step: 50/439, Loss: 0.8105\n",
      "Iteration: 4/15, Step: 60/439, Loss: 1.0014\n",
      "Iteration: 4/15, Step: 70/439, Loss: 1.3308\n",
      "Iteration: 4/15, Step: 80/439, Loss: 0.8445\n",
      "Iteration: 4/15, Step: 90/439, Loss: 0.8658\n",
      "Iteration: 4/15, Step: 100/439, Loss: 0.8709\n",
      "Iteration: 4/15, Step: 110/439, Loss: 1.0063\n",
      "Iteration: 4/15, Step: 120/439, Loss: 0.8079\n",
      "Iteration: 4/15, Step: 130/439, Loss: 0.9173\n",
      "Iteration: 4/15, Step: 140/439, Loss: 1.4890\n",
      "Iteration: 4/15, Step: 150/439, Loss: 1.0793\n",
      "Iteration: 4/15, Step: 160/439, Loss: 1.0120\n",
      "Iteration: 4/15, Step: 170/439, Loss: 0.9632\n",
      "Iteration: 4/15, Step: 180/439, Loss: 0.9009\n",
      "Iteration: 4/15, Step: 190/439, Loss: 0.9343\n",
      "Iteration: 4/15, Step: 200/439, Loss: 0.7334\n",
      "Iteration: 4/15, Step: 210/439, Loss: 0.8955\n",
      "Iteration: 4/15, Step: 220/439, Loss: 1.5928\n",
      "Iteration: 4/15, Step: 230/439, Loss: 1.0180\n",
      "Iteration: 4/15, Step: 240/439, Loss: 1.0386\n",
      "Iteration: 4/15, Step: 250/439, Loss: 1.0154\n",
      "Iteration: 4/15, Step: 260/439, Loss: 0.7862\n",
      "Iteration: 4/15, Step: 270/439, Loss: 1.0881\n",
      "Iteration: 4/15, Step: 280/439, Loss: 0.8526\n",
      "Iteration: 4/15, Step: 290/439, Loss: 0.7770\n",
      "Iteration: 4/15, Step: 300/439, Loss: 0.9733\n",
      "Iteration: 4/15, Step: 310/439, Loss: 0.7423\n",
      "Iteration: 4/15, Step: 320/439, Loss: 1.0464\n",
      "Iteration: 4/15, Step: 330/439, Loss: 0.9055\n",
      "Iteration: 4/15, Step: 340/439, Loss: 0.7660\n",
      "Iteration: 4/15, Step: 350/439, Loss: 1.1900\n",
      "Iteration: 4/15, Step: 360/439, Loss: 1.0189\n",
      "Iteration: 4/15, Step: 370/439, Loss: 1.0182\n",
      "Iteration: 4/15, Step: 380/439, Loss: 1.0869\n",
      "Iteration: 4/15, Step: 390/439, Loss: 0.9230\n",
      "Iteration: 4/15, Step: 400/439, Loss: 1.2510\n",
      "Iteration: 4/15, Step: 410/439, Loss: 0.8156\n",
      "Iteration: 4/15, Step: 420/439, Loss: 1.2624\n",
      "Iteration: 4/15, Step: 430/439, Loss: 0.8905\n",
      "Iteration: 4/15, Test accuracy: 63.0952\n",
      "Iteration: 5/15, Step: 10/439, Loss: 1.0575\n",
      "Iteration: 5/15, Step: 20/439, Loss: 1.2329\n",
      "Iteration: 5/15, Step: 30/439, Loss: 0.9122\n",
      "Iteration: 5/15, Step: 40/439, Loss: 1.2473\n",
      "Iteration: 5/15, Step: 50/439, Loss: 0.8880\n",
      "Iteration: 5/15, Step: 60/439, Loss: 0.8900\n",
      "Iteration: 5/15, Step: 70/439, Loss: 1.4587\n",
      "Iteration: 5/15, Step: 80/439, Loss: 0.9384\n",
      "Iteration: 5/15, Step: 90/439, Loss: 0.9044\n",
      "Iteration: 5/15, Step: 100/439, Loss: 1.0300\n",
      "Iteration: 5/15, Step: 110/439, Loss: 0.9645\n",
      "Iteration: 5/15, Step: 120/439, Loss: 0.9283\n",
      "Iteration: 5/15, Step: 130/439, Loss: 0.8288\n",
      "Iteration: 5/15, Step: 140/439, Loss: 1.1767\n",
      "Iteration: 5/15, Step: 150/439, Loss: 1.3163\n",
      "Iteration: 5/15, Step: 160/439, Loss: 0.8945\n",
      "Iteration: 5/15, Step: 170/439, Loss: 0.7880\n",
      "Iteration: 5/15, Step: 180/439, Loss: 0.8857\n",
      "Iteration: 5/15, Step: 190/439, Loss: 0.9848\n",
      "Iteration: 5/15, Step: 200/439, Loss: 0.9752\n",
      "Iteration: 5/15, Step: 210/439, Loss: 1.0885\n",
      "Iteration: 5/15, Step: 220/439, Loss: 0.9909\n",
      "Iteration: 5/15, Step: 230/439, Loss: 0.7337\n",
      "Iteration: 5/15, Step: 240/439, Loss: 0.6732\n",
      "Iteration: 5/15, Step: 250/439, Loss: 0.9469\n",
      "Iteration: 5/15, Step: 260/439, Loss: 1.0953\n",
      "Iteration: 5/15, Step: 270/439, Loss: 1.0876\n",
      "Iteration: 5/15, Step: 280/439, Loss: 0.8688\n",
      "Iteration: 5/15, Step: 290/439, Loss: 0.7964\n",
      "Iteration: 5/15, Step: 300/439, Loss: 1.0208\n",
      "Iteration: 5/15, Step: 310/439, Loss: 0.9588\n",
      "Iteration: 5/15, Step: 320/439, Loss: 1.0973\n",
      "Iteration: 5/15, Step: 330/439, Loss: 0.9779\n",
      "Iteration: 5/15, Step: 340/439, Loss: 0.9881\n",
      "Iteration: 5/15, Step: 350/439, Loss: 0.7939\n",
      "Iteration: 5/15, Step: 360/439, Loss: 1.2795\n",
      "Iteration: 5/15, Step: 370/439, Loss: 0.8627\n",
      "Iteration: 5/15, Step: 380/439, Loss: 0.6729\n",
      "Iteration: 5/15, Step: 390/439, Loss: 0.8915\n",
      "Iteration: 5/15, Step: 400/439, Loss: 0.8790\n",
      "Iteration: 5/15, Step: 410/439, Loss: 0.9672\n",
      "Iteration: 5/15, Step: 420/439, Loss: 0.9845\n",
      "Iteration: 5/15, Step: 430/439, Loss: 1.4432\n",
      "Iteration: 5/15, Test accuracy: 69.4762\n",
      "Iteration: 6/15, Step: 10/439, Loss: 0.7526\n",
      "Iteration: 6/15, Step: 20/439, Loss: 0.7381\n",
      "Iteration: 6/15, Step: 30/439, Loss: 0.8973\n",
      "Iteration: 6/15, Step: 40/439, Loss: 0.7500\n",
      "Iteration: 6/15, Step: 50/439, Loss: 0.7310\n",
      "Iteration: 6/15, Step: 60/439, Loss: 0.7404\n",
      "Iteration: 6/15, Step: 70/439, Loss: 1.0069\n",
      "Iteration: 6/15, Step: 80/439, Loss: 0.9992\n",
      "Iteration: 6/15, Step: 90/439, Loss: 0.6839\n",
      "Iteration: 6/15, Step: 100/439, Loss: 0.8631\n",
      "Iteration: 6/15, Step: 110/439, Loss: 1.0198\n",
      "Iteration: 6/15, Step: 120/439, Loss: 0.9694\n",
      "Iteration: 6/15, Step: 130/439, Loss: 1.2855\n",
      "Iteration: 6/15, Step: 140/439, Loss: 1.1726\n",
      "Iteration: 6/15, Step: 150/439, Loss: 0.9504\n",
      "Iteration: 6/15, Step: 160/439, Loss: 1.0423\n",
      "Iteration: 6/15, Step: 170/439, Loss: 1.1584\n",
      "Iteration: 6/15, Step: 180/439, Loss: 0.7793\n",
      "Iteration: 6/15, Step: 190/439, Loss: 0.9542\n",
      "Iteration: 6/15, Step: 200/439, Loss: 0.9975\n",
      "Iteration: 6/15, Step: 210/439, Loss: 0.7429\n",
      "Iteration: 6/15, Step: 220/439, Loss: 0.9317\n",
      "Iteration: 6/15, Step: 230/439, Loss: 1.0949\n",
      "Iteration: 6/15, Step: 240/439, Loss: 0.8223\n",
      "Iteration: 6/15, Step: 250/439, Loss: 0.9032\n",
      "Iteration: 6/15, Step: 260/439, Loss: 1.1498\n",
      "Iteration: 6/15, Step: 270/439, Loss: 0.8692\n",
      "Iteration: 6/15, Step: 280/439, Loss: 0.8349\n",
      "Iteration: 6/15, Step: 290/439, Loss: 0.9683\n",
      "Iteration: 6/15, Step: 300/439, Loss: 0.7239\n",
      "Iteration: 6/15, Step: 310/439, Loss: 0.8074\n",
      "Iteration: 6/15, Step: 320/439, Loss: 1.0968\n",
      "Iteration: 6/15, Step: 330/439, Loss: 0.9713\n",
      "Iteration: 6/15, Step: 340/439, Loss: 0.7779\n",
      "Iteration: 6/15, Step: 350/439, Loss: 0.8656\n",
      "Iteration: 6/15, Step: 360/439, Loss: 0.8084\n",
      "Iteration: 6/15, Step: 370/439, Loss: 0.9317\n",
      "Iteration: 6/15, Step: 380/439, Loss: 0.8319\n",
      "Iteration: 6/15, Step: 390/439, Loss: 0.7294\n",
      "Iteration: 6/15, Step: 400/439, Loss: 1.0115\n",
      "Iteration: 6/15, Step: 410/439, Loss: 1.1272\n",
      "Iteration: 6/15, Step: 420/439, Loss: 1.1785\n",
      "Iteration: 6/15, Step: 430/439, Loss: 1.4017\n",
      "Iteration: 6/15, Test accuracy: 68.7619\n",
      "Iteration: 7/15, Step: 10/439, Loss: 1.0702\n",
      "Iteration: 7/15, Step: 20/439, Loss: 0.8754\n",
      "Iteration: 7/15, Step: 30/439, Loss: 1.0604\n",
      "Iteration: 7/15, Step: 40/439, Loss: 1.0263\n",
      "Iteration: 7/15, Step: 50/439, Loss: 0.7646\n",
      "Iteration: 7/15, Step: 60/439, Loss: 0.8497\n",
      "Iteration: 7/15, Step: 70/439, Loss: 0.9456\n",
      "Iteration: 7/15, Step: 80/439, Loss: 0.8589\n",
      "Iteration: 7/15, Step: 90/439, Loss: 1.0139\n",
      "Iteration: 7/15, Step: 100/439, Loss: 1.0810\n",
      "Iteration: 7/15, Step: 110/439, Loss: 1.2087\n",
      "Iteration: 7/15, Step: 120/439, Loss: 0.8031\n",
      "Iteration: 7/15, Step: 130/439, Loss: 0.7870\n",
      "Iteration: 7/15, Step: 140/439, Loss: 0.8270\n",
      "Iteration: 7/15, Step: 150/439, Loss: 0.8277\n",
      "Iteration: 7/15, Step: 160/439, Loss: 1.2470\n",
      "Iteration: 7/15, Step: 170/439, Loss: 1.2704\n",
      "Iteration: 7/15, Step: 180/439, Loss: 0.9209\n",
      "Iteration: 7/15, Step: 190/439, Loss: 1.3502\n",
      "Iteration: 7/15, Step: 200/439, Loss: 1.2435\n",
      "Iteration: 7/15, Step: 210/439, Loss: 1.0219\n",
      "Iteration: 7/15, Step: 220/439, Loss: 0.8482\n",
      "Iteration: 7/15, Step: 230/439, Loss: 0.9954\n",
      "Iteration: 7/15, Step: 240/439, Loss: 1.0319\n",
      "Iteration: 7/15, Step: 250/439, Loss: 0.6995\n",
      "Iteration: 7/15, Step: 260/439, Loss: 0.7085\n",
      "Iteration: 7/15, Step: 270/439, Loss: 0.8914\n",
      "Iteration: 7/15, Step: 280/439, Loss: 0.6697\n",
      "Iteration: 7/15, Step: 290/439, Loss: 1.1178\n",
      "Iteration: 7/15, Step: 300/439, Loss: 0.8499\n",
      "Iteration: 7/15, Step: 310/439, Loss: 1.0817\n",
      "Iteration: 7/15, Step: 320/439, Loss: 1.0007\n",
      "Iteration: 7/15, Step: 330/439, Loss: 0.8392\n",
      "Iteration: 7/15, Step: 340/439, Loss: 0.9439\n",
      "Iteration: 7/15, Step: 350/439, Loss: 0.7241\n",
      "Iteration: 7/15, Step: 360/439, Loss: 0.9741\n",
      "Iteration: 7/15, Step: 370/439, Loss: 0.6086\n",
      "Iteration: 7/15, Step: 380/439, Loss: 0.7352\n",
      "Iteration: 7/15, Step: 390/439, Loss: 1.0716\n",
      "Iteration: 7/15, Step: 400/439, Loss: 1.0958\n",
      "Iteration: 7/15, Step: 410/439, Loss: 1.0800\n",
      "Iteration: 7/15, Step: 420/439, Loss: 0.8073\n",
      "Iteration: 7/15, Step: 430/439, Loss: 0.8843\n",
      "Iteration: 7/15, Test accuracy: 70.1905\n",
      "Iteration: 8/15, Step: 10/439, Loss: 0.9569\n",
      "Iteration: 8/15, Step: 20/439, Loss: 0.7974\n",
      "Iteration: 8/15, Step: 30/439, Loss: 0.7363\n",
      "Iteration: 8/15, Step: 40/439, Loss: 0.8368\n",
      "Iteration: 8/15, Step: 50/439, Loss: 0.6682\n",
      "Iteration: 8/15, Step: 60/439, Loss: 0.8008\n",
      "Iteration: 8/15, Step: 70/439, Loss: 0.9703\n",
      "Iteration: 8/15, Step: 80/439, Loss: 0.8628\n",
      "Iteration: 8/15, Step: 90/439, Loss: 0.9393\n",
      "Iteration: 8/15, Step: 100/439, Loss: 0.8635\n",
      "Iteration: 8/15, Step: 110/439, Loss: 0.7533\n",
      "Iteration: 8/15, Step: 120/439, Loss: 0.6931\n",
      "Iteration: 8/15, Step: 130/439, Loss: 1.0328\n",
      "Iteration: 8/15, Step: 140/439, Loss: 0.7801\n",
      "Iteration: 8/15, Step: 150/439, Loss: 1.2791\n",
      "Iteration: 8/15, Step: 160/439, Loss: 0.9855\n",
      "Iteration: 8/15, Step: 170/439, Loss: 0.8967\n",
      "Iteration: 8/15, Step: 180/439, Loss: 0.6972\n",
      "Iteration: 8/15, Step: 190/439, Loss: 0.8121\n",
      "Iteration: 8/15, Step: 200/439, Loss: 1.1463\n",
      "Iteration: 8/15, Step: 210/439, Loss: 0.7358\n",
      "Iteration: 8/15, Step: 220/439, Loss: 0.7724\n",
      "Iteration: 8/15, Step: 230/439, Loss: 1.0654\n",
      "Iteration: 8/15, Step: 240/439, Loss: 0.7853\n",
      "Iteration: 8/15, Step: 250/439, Loss: 0.5957\n",
      "Iteration: 8/15, Step: 260/439, Loss: 0.8305\n",
      "Iteration: 8/15, Step: 270/439, Loss: 0.9182\n",
      "Iteration: 8/15, Step: 280/439, Loss: 0.8236\n",
      "Iteration: 8/15, Step: 290/439, Loss: 0.8266\n",
      "Iteration: 8/15, Step: 300/439, Loss: 0.8584\n",
      "Iteration: 8/15, Step: 310/439, Loss: 0.9949\n",
      "Iteration: 8/15, Step: 320/439, Loss: 0.9301\n",
      "Iteration: 8/15, Step: 330/439, Loss: 0.9898\n",
      "Iteration: 8/15, Step: 340/439, Loss: 0.8426\n",
      "Iteration: 8/15, Step: 350/439, Loss: 0.8452\n",
      "Iteration: 8/15, Step: 360/439, Loss: 0.9219\n",
      "Iteration: 8/15, Step: 370/439, Loss: 0.6739\n",
      "Iteration: 8/15, Step: 380/439, Loss: 0.6740\n",
      "Iteration: 8/15, Step: 390/439, Loss: 0.7302\n",
      "Iteration: 8/15, Step: 400/439, Loss: 1.2787\n",
      "Iteration: 8/15, Step: 410/439, Loss: 1.1427\n",
      "Iteration: 8/15, Step: 420/439, Loss: 0.7681\n",
      "Iteration: 8/15, Step: 430/439, Loss: 0.8072\n",
      "Iteration: 8/15, Test accuracy: 57.8095\n",
      "Iteration: 9/15, Step: 10/439, Loss: 1.3169\n",
      "Iteration: 9/15, Step: 20/439, Loss: 1.0481\n",
      "Iteration: 9/15, Step: 30/439, Loss: 1.3718\n",
      "Iteration: 9/15, Step: 40/439, Loss: 1.0363\n",
      "Iteration: 9/15, Step: 50/439, Loss: 1.0416\n",
      "Iteration: 9/15, Step: 60/439, Loss: 0.8309\n",
      "Iteration: 9/15, Step: 70/439, Loss: 0.8368\n",
      "Iteration: 9/15, Step: 80/439, Loss: 0.8720\n",
      "Iteration: 9/15, Step: 90/439, Loss: 0.6576\n",
      "Iteration: 9/15, Step: 100/439, Loss: 0.6782\n",
      "Iteration: 9/15, Step: 110/439, Loss: 0.9138\n",
      "Iteration: 9/15, Step: 120/439, Loss: 0.7166\n",
      "Iteration: 9/15, Step: 130/439, Loss: 0.7500\n",
      "Iteration: 9/15, Step: 140/439, Loss: 0.8400\n",
      "Iteration: 9/15, Step: 150/439, Loss: 0.6909\n",
      "Iteration: 9/15, Step: 160/439, Loss: 0.7820\n",
      "Iteration: 9/15, Step: 170/439, Loss: 1.0444\n",
      "Iteration: 9/15, Step: 180/439, Loss: 0.9319\n",
      "Iteration: 9/15, Step: 190/439, Loss: 1.0630\n",
      "Iteration: 9/15, Step: 200/439, Loss: 1.0789\n",
      "Iteration: 9/15, Step: 210/439, Loss: 0.7466\n",
      "Iteration: 9/15, Step: 220/439, Loss: 1.0929\n",
      "Iteration: 9/15, Step: 230/439, Loss: 0.7634\n",
      "Iteration: 9/15, Step: 240/439, Loss: 1.0314\n",
      "Iteration: 9/15, Step: 250/439, Loss: 0.9770\n",
      "Iteration: 9/15, Step: 260/439, Loss: 0.6053\n",
      "Iteration: 9/15, Step: 270/439, Loss: 0.9591\n",
      "Iteration: 9/15, Step: 280/439, Loss: 0.8140\n",
      "Iteration: 9/15, Step: 290/439, Loss: 0.6931\n",
      "Iteration: 9/15, Step: 300/439, Loss: 0.7382\n",
      "Iteration: 9/15, Step: 310/439, Loss: 0.7228\n",
      "Iteration: 9/15, Step: 320/439, Loss: 0.9503\n",
      "Iteration: 9/15, Step: 330/439, Loss: 0.8136\n",
      "Iteration: 9/15, Step: 340/439, Loss: 0.7382\n",
      "Iteration: 9/15, Step: 350/439, Loss: 0.6356\n",
      "Iteration: 9/15, Step: 360/439, Loss: 0.9172\n",
      "Iteration: 9/15, Step: 370/439, Loss: 0.8744\n",
      "Iteration: 9/15, Step: 380/439, Loss: 0.9404\n",
      "Iteration: 9/15, Step: 390/439, Loss: 0.5202\n",
      "Iteration: 9/15, Step: 400/439, Loss: 1.0736\n",
      "Iteration: 9/15, Step: 410/439, Loss: 0.6810\n",
      "Iteration: 9/15, Step: 420/439, Loss: 0.8137\n",
      "Iteration: 9/15, Step: 430/439, Loss: 0.8486\n",
      "Iteration: 9/15, Test accuracy: 71.0000\n",
      "Iteration: 10/15, Step: 10/439, Loss: 1.0364\n",
      "Iteration: 10/15, Step: 20/439, Loss: 0.8067\n",
      "Iteration: 10/15, Step: 30/439, Loss: 0.8315\n",
      "Iteration: 10/15, Step: 40/439, Loss: 0.7563\n",
      "Iteration: 10/15, Step: 50/439, Loss: 0.8694\n",
      "Iteration: 10/15, Step: 60/439, Loss: 0.7077\n",
      "Iteration: 10/15, Step: 70/439, Loss: 0.8590\n",
      "Iteration: 10/15, Step: 80/439, Loss: 0.7088\n",
      "Iteration: 10/15, Step: 90/439, Loss: 0.8818\n",
      "Iteration: 10/15, Step: 100/439, Loss: 1.2411\n",
      "Iteration: 10/15, Step: 110/439, Loss: 0.8393\n",
      "Iteration: 10/15, Step: 120/439, Loss: 0.8429\n",
      "Iteration: 10/15, Step: 130/439, Loss: 1.0724\n",
      "Iteration: 10/15, Step: 140/439, Loss: 0.9928\n",
      "Iteration: 10/15, Step: 150/439, Loss: 0.6606\n",
      "Iteration: 10/15, Step: 160/439, Loss: 0.7343\n",
      "Iteration: 10/15, Step: 170/439, Loss: 0.7636\n",
      "Iteration: 10/15, Step: 180/439, Loss: 0.9374\n",
      "Iteration: 10/15, Step: 190/439, Loss: 0.7471\n",
      "Iteration: 10/15, Step: 200/439, Loss: 0.8701\n",
      "Iteration: 10/15, Step: 210/439, Loss: 1.0516\n",
      "Iteration: 10/15, Step: 220/439, Loss: 0.7485\n",
      "Iteration: 10/15, Step: 230/439, Loss: 0.6815\n",
      "Iteration: 10/15, Step: 240/439, Loss: 0.8602\n",
      "Iteration: 10/15, Step: 250/439, Loss: 0.7052\n",
      "Iteration: 10/15, Step: 260/439, Loss: 1.0195\n",
      "Iteration: 10/15, Step: 270/439, Loss: 0.7645\n",
      "Iteration: 10/15, Step: 280/439, Loss: 1.0026\n",
      "Iteration: 10/15, Step: 290/439, Loss: 0.8119\n",
      "Iteration: 10/15, Step: 300/439, Loss: 0.5589\n",
      "Iteration: 10/15, Step: 310/439, Loss: 0.9710\n",
      "Iteration: 10/15, Step: 320/439, Loss: 0.6125\n",
      "Iteration: 10/15, Step: 330/439, Loss: 0.7842\n",
      "Iteration: 10/15, Step: 340/439, Loss: 0.5827\n",
      "Iteration: 10/15, Step: 350/439, Loss: 0.8284\n",
      "Iteration: 10/15, Step: 360/439, Loss: 0.6069\n",
      "Iteration: 10/15, Step: 370/439, Loss: 0.6501\n",
      "Iteration: 10/15, Step: 380/439, Loss: 0.8594\n",
      "Iteration: 10/15, Step: 390/439, Loss: 0.7537\n",
      "Iteration: 10/15, Step: 400/439, Loss: 0.8207\n",
      "Iteration: 10/15, Step: 410/439, Loss: 0.8676\n",
      "Iteration: 10/15, Step: 420/439, Loss: 0.9147\n",
      "Iteration: 10/15, Step: 430/439, Loss: 1.0456\n",
      "Iteration: 10/15, Test accuracy: 72.8571\n",
      "Iteration: 11/15, Step: 10/439, Loss: 0.9295\n",
      "Iteration: 11/15, Step: 20/439, Loss: 1.1590\n",
      "Iteration: 11/15, Step: 30/439, Loss: 0.5994\n",
      "Iteration: 11/15, Step: 40/439, Loss: 0.7681\n",
      "Iteration: 11/15, Step: 50/439, Loss: 0.7318\n",
      "Iteration: 11/15, Step: 60/439, Loss: 0.6169\n",
      "Iteration: 11/15, Step: 70/439, Loss: 0.4582\n",
      "Iteration: 11/15, Step: 80/439, Loss: 0.5783\n",
      "Iteration: 11/15, Step: 90/439, Loss: 0.5817\n",
      "Iteration: 11/15, Step: 100/439, Loss: 0.7143\n",
      "Iteration: 11/15, Step: 110/439, Loss: 0.6182\n",
      "Iteration: 11/15, Step: 120/439, Loss: 0.6861\n",
      "Iteration: 11/15, Step: 130/439, Loss: 0.7439\n",
      "Iteration: 11/15, Step: 140/439, Loss: 0.7469\n",
      "Iteration: 11/15, Step: 150/439, Loss: 0.7007\n",
      "Iteration: 11/15, Step: 160/439, Loss: 0.9461\n",
      "Iteration: 11/15, Step: 170/439, Loss: 0.9479\n",
      "Iteration: 11/15, Step: 180/439, Loss: 0.7781\n",
      "Iteration: 11/15, Step: 190/439, Loss: 0.7223\n",
      "Iteration: 11/15, Step: 200/439, Loss: 0.7001\n",
      "Iteration: 11/15, Step: 210/439, Loss: 0.9645\n",
      "Iteration: 11/15, Step: 220/439, Loss: 0.8353\n",
      "Iteration: 11/15, Step: 230/439, Loss: 0.6575\n",
      "Iteration: 11/15, Step: 240/439, Loss: 0.7821\n",
      "Iteration: 11/15, Step: 250/439, Loss: 0.7139\n",
      "Iteration: 11/15, Step: 260/439, Loss: 0.8177\n",
      "Iteration: 11/15, Step: 270/439, Loss: 0.5553\n",
      "Iteration: 11/15, Step: 280/439, Loss: 0.8741\n",
      "Iteration: 11/15, Step: 290/439, Loss: 0.7327\n",
      "Iteration: 11/15, Step: 300/439, Loss: 1.0403\n",
      "Iteration: 11/15, Step: 310/439, Loss: 0.7393\n",
      "Iteration: 11/15, Step: 320/439, Loss: 0.8344\n",
      "Iteration: 11/15, Step: 330/439, Loss: 0.8673\n",
      "Iteration: 11/15, Step: 340/439, Loss: 0.9008\n",
      "Iteration: 11/15, Step: 350/439, Loss: 0.8119\n",
      "Iteration: 11/15, Step: 360/439, Loss: 0.7462\n",
      "Iteration: 11/15, Step: 370/439, Loss: 0.8425\n",
      "Iteration: 11/15, Step: 380/439, Loss: 0.7850\n",
      "Iteration: 11/15, Step: 390/439, Loss: 0.8894\n",
      "Iteration: 11/15, Step: 400/439, Loss: 0.7524\n",
      "Iteration: 11/15, Step: 410/439, Loss: 0.5807\n",
      "Iteration: 11/15, Step: 420/439, Loss: 0.9908\n",
      "Iteration: 11/15, Step: 430/439, Loss: 0.9143\n",
      "Iteration: 11/15, Test accuracy: 73.2381\n",
      "Iteration: 12/15, Step: 10/439, Loss: 0.7871\n",
      "Iteration: 12/15, Step: 20/439, Loss: 0.8590\n",
      "Iteration: 12/15, Step: 30/439, Loss: 0.9039\n",
      "Iteration: 12/15, Step: 40/439, Loss: 0.8370\n",
      "Iteration: 12/15, Step: 50/439, Loss: 0.7848\n",
      "Iteration: 12/15, Step: 60/439, Loss: 0.6387\n",
      "Iteration: 12/15, Step: 70/439, Loss: 0.8644\n",
      "Iteration: 12/15, Step: 80/439, Loss: 0.4637\n",
      "Iteration: 12/15, Step: 90/439, Loss: 0.8114\n",
      "Iteration: 12/15, Step: 100/439, Loss: 0.5525\n",
      "Iteration: 12/15, Step: 110/439, Loss: 0.8075\n",
      "Iteration: 12/15, Step: 120/439, Loss: 0.7871\n",
      "Iteration: 12/15, Step: 130/439, Loss: 1.0141\n",
      "Iteration: 12/15, Step: 140/439, Loss: 0.7434\n",
      "Iteration: 12/15, Step: 150/439, Loss: 1.2283\n",
      "Iteration: 12/15, Step: 160/439, Loss: 0.9639\n",
      "Iteration: 12/15, Step: 170/439, Loss: 0.8204\n",
      "Iteration: 12/15, Step: 180/439, Loss: 0.9312\n",
      "Iteration: 12/15, Step: 190/439, Loss: 0.8731\n",
      "Iteration: 12/15, Step: 200/439, Loss: 0.8286\n",
      "Iteration: 12/15, Step: 210/439, Loss: 1.1422\n",
      "Iteration: 12/15, Step: 220/439, Loss: 0.7382\n",
      "Iteration: 12/15, Step: 230/439, Loss: 1.0164\n",
      "Iteration: 12/15, Step: 240/439, Loss: 0.6917\n",
      "Iteration: 12/15, Step: 250/439, Loss: 0.7818\n",
      "Iteration: 12/15, Step: 260/439, Loss: 0.7590\n",
      "Iteration: 12/15, Step: 270/439, Loss: 0.7393\n",
      "Iteration: 12/15, Step: 280/439, Loss: 0.5293\n",
      "Iteration: 12/15, Step: 290/439, Loss: 0.8445\n",
      "Iteration: 12/15, Step: 300/439, Loss: 0.8024\n",
      "Iteration: 12/15, Step: 310/439, Loss: 1.0181\n",
      "Iteration: 12/15, Step: 320/439, Loss: 0.4583\n",
      "Iteration: 12/15, Step: 330/439, Loss: 0.6678\n",
      "Iteration: 12/15, Step: 340/439, Loss: 1.0179\n",
      "Iteration: 12/15, Step: 350/439, Loss: 0.8924\n",
      "Iteration: 12/15, Step: 360/439, Loss: 0.5344\n",
      "Iteration: 12/15, Step: 370/439, Loss: 0.4312\n",
      "Iteration: 12/15, Step: 380/439, Loss: 0.5667\n",
      "Iteration: 12/15, Step: 390/439, Loss: 0.7668\n",
      "Iteration: 12/15, Step: 400/439, Loss: 0.7517\n",
      "Iteration: 12/15, Step: 410/439, Loss: 0.8248\n",
      "Iteration: 12/15, Step: 420/439, Loss: 0.6830\n",
      "Iteration: 12/15, Step: 430/439, Loss: 0.7497\n",
      "Iteration: 12/15, Test accuracy: 73.4762\n",
      "Iteration: 13/15, Step: 10/439, Loss: 0.6760\n",
      "Iteration: 13/15, Step: 20/439, Loss: 0.7028\n",
      "Iteration: 13/15, Step: 30/439, Loss: 0.4868\n",
      "Iteration: 13/15, Step: 40/439, Loss: 0.8132\n",
      "Iteration: 13/15, Step: 50/439, Loss: 0.6744\n",
      "Iteration: 13/15, Step: 60/439, Loss: 0.9356\n",
      "Iteration: 13/15, Step: 70/439, Loss: 0.7200\n",
      "Iteration: 13/15, Step: 80/439, Loss: 0.8291\n",
      "Iteration: 13/15, Step: 90/439, Loss: 0.5942\n",
      "Iteration: 13/15, Step: 100/439, Loss: 1.0339\n",
      "Iteration: 13/15, Step: 110/439, Loss: 0.8511\n",
      "Iteration: 13/15, Step: 120/439, Loss: 0.8965\n",
      "Iteration: 13/15, Step: 130/439, Loss: 1.1515\n",
      "Iteration: 13/15, Step: 140/439, Loss: 0.8640\n",
      "Iteration: 13/15, Step: 150/439, Loss: 0.7077\n",
      "Iteration: 13/15, Step: 160/439, Loss: 0.6696\n",
      "Iteration: 13/15, Step: 170/439, Loss: 0.9151\n",
      "Iteration: 13/15, Step: 180/439, Loss: 0.7075\n",
      "Iteration: 13/15, Step: 190/439, Loss: 0.6142\n",
      "Iteration: 13/15, Step: 200/439, Loss: 1.0119\n",
      "Iteration: 13/15, Step: 210/439, Loss: 0.5205\n",
      "Iteration: 13/15, Step: 220/439, Loss: 0.7687\n",
      "Iteration: 13/15, Step: 230/439, Loss: 0.8957\n",
      "Iteration: 13/15, Step: 240/439, Loss: 0.7698\n",
      "Iteration: 13/15, Step: 250/439, Loss: 0.6774\n",
      "Iteration: 13/15, Step: 260/439, Loss: 0.5804\n",
      "Iteration: 13/15, Step: 270/439, Loss: 0.5146\n",
      "Iteration: 13/15, Step: 280/439, Loss: 0.8328\n",
      "Iteration: 13/15, Step: 290/439, Loss: 0.8172\n",
      "Iteration: 13/15, Step: 300/439, Loss: 0.4928\n",
      "Iteration: 13/15, Step: 310/439, Loss: 0.8259\n",
      "Iteration: 13/15, Step: 320/439, Loss: 0.6418\n",
      "Iteration: 13/15, Step: 330/439, Loss: 0.7353\n",
      "Iteration: 13/15, Step: 340/439, Loss: 0.8074\n",
      "Iteration: 13/15, Step: 350/439, Loss: 0.6366\n",
      "Iteration: 13/15, Step: 360/439, Loss: 0.4578\n",
      "Iteration: 13/15, Step: 370/439, Loss: 1.2728\n",
      "Iteration: 13/15, Step: 380/439, Loss: 0.6938\n",
      "Iteration: 13/15, Step: 390/439, Loss: 0.9658\n",
      "Iteration: 13/15, Step: 400/439, Loss: 0.6729\n",
      "Iteration: 13/15, Step: 410/439, Loss: 0.6395\n",
      "Iteration: 13/15, Step: 420/439, Loss: 0.6966\n",
      "Iteration: 13/15, Step: 430/439, Loss: 0.3874\n",
      "Iteration: 13/15, Test accuracy: 74.0000\n",
      "Iteration: 14/15, Step: 10/439, Loss: 0.7210\n",
      "Iteration: 14/15, Step: 20/439, Loss: 0.5182\n",
      "Iteration: 14/15, Step: 30/439, Loss: 0.7378\n",
      "Iteration: 14/15, Step: 40/439, Loss: 0.7532\n",
      "Iteration: 14/15, Step: 50/439, Loss: 0.7826\n",
      "Iteration: 14/15, Step: 60/439, Loss: 0.5929\n",
      "Iteration: 14/15, Step: 70/439, Loss: 0.7303\n",
      "Iteration: 14/15, Step: 80/439, Loss: 0.7613\n",
      "Iteration: 14/15, Step: 90/439, Loss: 0.5753\n",
      "Iteration: 14/15, Step: 100/439, Loss: 1.0927\n",
      "Iteration: 14/15, Step: 110/439, Loss: 0.7704\n",
      "Iteration: 14/15, Step: 120/439, Loss: 0.8515\n",
      "Iteration: 14/15, Step: 130/439, Loss: 0.7902\n",
      "Iteration: 14/15, Step: 140/439, Loss: 1.2900\n",
      "Iteration: 14/15, Step: 150/439, Loss: 1.2871\n",
      "Iteration: 14/15, Step: 160/439, Loss: 0.7257\n",
      "Iteration: 14/15, Step: 170/439, Loss: 0.6523\n",
      "Iteration: 14/15, Step: 180/439, Loss: 0.6153\n",
      "Iteration: 14/15, Step: 190/439, Loss: 0.9887\n",
      "Iteration: 14/15, Step: 200/439, Loss: 0.8553\n",
      "Iteration: 14/15, Step: 210/439, Loss: 0.7214\n",
      "Iteration: 14/15, Step: 220/439, Loss: 0.6793\n",
      "Iteration: 14/15, Step: 230/439, Loss: 0.6694\n",
      "Iteration: 14/15, Step: 240/439, Loss: 0.5890\n",
      "Iteration: 14/15, Step: 250/439, Loss: 0.7053\n",
      "Iteration: 14/15, Step: 260/439, Loss: 0.7544\n",
      "Iteration: 14/15, Step: 270/439, Loss: 0.6774\n",
      "Iteration: 14/15, Step: 280/439, Loss: 0.7644\n",
      "Iteration: 14/15, Step: 290/439, Loss: 0.5182\n",
      "Iteration: 14/15, Step: 300/439, Loss: 0.6332\n",
      "Iteration: 14/15, Step: 310/439, Loss: 0.9711\n",
      "Iteration: 14/15, Step: 320/439, Loss: 0.5559\n",
      "Iteration: 14/15, Step: 330/439, Loss: 0.9071\n",
      "Iteration: 14/15, Step: 340/439, Loss: 0.5348\n",
      "Iteration: 14/15, Step: 350/439, Loss: 0.9929\n",
      "Iteration: 14/15, Step: 360/439, Loss: 0.8281\n",
      "Iteration: 14/15, Step: 370/439, Loss: 0.6453\n",
      "Iteration: 14/15, Step: 380/439, Loss: 0.8165\n",
      "Iteration: 14/15, Step: 390/439, Loss: 0.4541\n",
      "Iteration: 14/15, Step: 400/439, Loss: 0.5541\n",
      "Iteration: 14/15, Step: 410/439, Loss: 0.5301\n",
      "Iteration: 14/15, Step: 420/439, Loss: 0.6911\n",
      "Iteration: 14/15, Step: 430/439, Loss: 1.0108\n",
      "Iteration: 14/15, Test accuracy: 74.2857\n",
      "Iteration: 15/15, Step: 10/439, Loss: 0.8389\n",
      "Iteration: 15/15, Step: 20/439, Loss: 0.7412\n",
      "Iteration: 15/15, Step: 30/439, Loss: 0.6010\n",
      "Iteration: 15/15, Step: 40/439, Loss: 0.8410\n",
      "Iteration: 15/15, Step: 50/439, Loss: 0.7525\n",
      "Iteration: 15/15, Step: 60/439, Loss: 0.6595\n",
      "Iteration: 15/15, Step: 70/439, Loss: 0.7513\n",
      "Iteration: 15/15, Step: 80/439, Loss: 0.8605\n",
      "Iteration: 15/15, Step: 90/439, Loss: 0.8933\n",
      "Iteration: 15/15, Step: 100/439, Loss: 0.5860\n",
      "Iteration: 15/15, Step: 110/439, Loss: 0.6041\n",
      "Iteration: 15/15, Step: 120/439, Loss: 0.3866\n",
      "Iteration: 15/15, Step: 130/439, Loss: 0.5032\n",
      "Iteration: 15/15, Step: 140/439, Loss: 0.7336\n",
      "Iteration: 15/15, Step: 150/439, Loss: 0.5921\n",
      "Iteration: 15/15, Step: 160/439, Loss: 0.6417\n",
      "Iteration: 15/15, Step: 170/439, Loss: 0.7061\n",
      "Iteration: 15/15, Step: 180/439, Loss: 0.7635\n",
      "Iteration: 15/15, Step: 190/439, Loss: 0.6236\n",
      "Iteration: 15/15, Step: 200/439, Loss: 0.6945\n",
      "Iteration: 15/15, Step: 210/439, Loss: 0.4758\n",
      "Iteration: 15/15, Step: 220/439, Loss: 0.8357\n",
      "Iteration: 15/15, Step: 230/439, Loss: 0.4725\n",
      "Iteration: 15/15, Step: 240/439, Loss: 0.4519\n",
      "Iteration: 15/15, Step: 250/439, Loss: 0.5149\n",
      "Iteration: 15/15, Step: 260/439, Loss: 0.6382\n",
      "Iteration: 15/15, Step: 270/439, Loss: 0.4744\n",
      "Iteration: 15/15, Step: 280/439, Loss: 0.6998\n",
      "Iteration: 15/15, Step: 290/439, Loss: 0.7193\n",
      "Iteration: 15/15, Step: 300/439, Loss: 0.7645\n",
      "Iteration: 15/15, Step: 310/439, Loss: 0.7894\n",
      "Iteration: 15/15, Step: 320/439, Loss: 0.7753\n",
      "Iteration: 15/15, Step: 330/439, Loss: 0.4863\n",
      "Iteration: 15/15, Step: 340/439, Loss: 0.8421\n",
      "Iteration: 15/15, Step: 350/439, Loss: 0.7935\n",
      "Iteration: 15/15, Step: 360/439, Loss: 0.7174\n",
      "Iteration: 15/15, Step: 370/439, Loss: 0.3617\n",
      "Iteration: 15/15, Step: 380/439, Loss: 0.6581\n",
      "Iteration: 15/15, Step: 390/439, Loss: 0.7786\n",
      "Iteration: 15/15, Step: 400/439, Loss: 0.5126\n",
      "Iteration: 15/15, Step: 410/439, Loss: 0.7050\n",
      "Iteration: 15/15, Step: 420/439, Loss: 0.3631\n",
      "Iteration: 15/15, Step: 430/439, Loss: 0.5742\n",
      "Iteration: 15/15, Test accuracy: 74.4762\n",
      "Best test accuracy: 74.4762\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "n_epochs = 15\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "best_test_acc = 0\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        y_pred = model(image)[0]\n",
    "        loss = loss_func(y_pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f'Iteration: {i+1}/{n_epochs}, Step: {idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_instances = len(test_loader)\n",
    "        n_correct = 0\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            y_pred = model(image)\n",
    "            pred = torch.argmax(y_pred, dim=1)\n",
    "            n_correct += (pred == label).sum().item()\n",
    "        test_acc = n_correct / n_instances\n",
    "        print(f'Iteration: {i+1}/{n_epochs}, Test accuracy: {test_acc:.4f}')\n",
    "        \n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(model, 'best_model.pth')\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "print(f'Best test accuracy: {best_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5124,
     "status": "ok",
     "timestamp": 1667717127189,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "xoB_kHvt8uSL"
   },
   "outputs": [],
   "source": [
    "!cp /content/best_model.pth /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3vtat6V4PRz"
   },
   "source": [
    "# 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 34016,
     "status": "ok",
     "timestamp": 1667717871387,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "8ipKOZVhtpLR"
   },
   "outputs": [],
   "source": [
    "best_model = torch.load('best_model.pth')\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for image, label in test_loader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        y_pred = best_model(image)\n",
    "        pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        y_trues.append(label.cpu().numpy())\n",
    "        y_preds.append(pred.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1667717871388,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "BXE46oNzALXp",
    "outputId": "4ba36758-75dc-4742-ea83-0844c6f3f5c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3559322 , 0.75728155, 0.51207729, 0.77777778, 0.50446429,\n",
       "       0.88470067, 0.93333333])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_preds = np.concatenate(y_preds)\n",
    "y_trues = np.concatenate(y_trues)\n",
    "\n",
    "scores = recall_score(y_trues, y_preds, average=None)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1667717871389,
     "user": {
      "displayName": "小·白菜",
      "userId": "11363145687516653892"
     },
     "user_tz": -480
    },
    "id": "qO8iYlqv4tQW",
    "outputId": "06631621-9828-4fa3-a192-00af7d2ce1ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.780828756864703"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_acc = accuracy_score(y_trues, y_preds)\n",
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
