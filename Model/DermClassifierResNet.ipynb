{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8q4ez2aLHF1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSP_bk2GJFjw",
        "outputId": "928175e7-eeb5-4f05-cb39-0098fdeb1f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcNJ6m5M2mJ",
        "outputId": "f2bfa977-2c97-4685-9bcb-a2442a3ffd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HAM10000_images_part_1\tHAM10000_segmentations_lesion_tschandl\n",
            "HAM10000_images_part_2\ttraining_data.csv\n",
            "HAM10000_metadata.csv\ttraining_data.npy\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/HAM10000\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WaP4GWyyONbA",
        "outputId": "b2f8615d-00ea-4f5e-cba3-890be3c9ca97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ISIC_0026769'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get metadata\n",
        "mdata = pd.read_csv(\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\")\n",
        "mdata\n",
        "mdata.iloc[2, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "pnPQuec9M9BM"
      },
      "outputs": [],
      "source": [
        "#transform the function according to the pytorch docs\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "img_size = 224\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    # transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# preprocess2 = preprocess = transforms.Compose([\n",
        "    \n",
        "# ])\n",
        "# input_tensor = preprocess(input_image)\n",
        "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "JzL3-QzYNDqz"
      },
      "outputs": [],
      "source": [
        "from pyparsing.helpers import identbodychars\n",
        "class DermClassHelper(): \n",
        "  #make images 50 x 50 to start \n",
        "  mdata = pd.read_csv(\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\")\n",
        "  IMG_SIZE = 224\n",
        "  labels = {}\n",
        "  img_map = {}\n",
        "  #training data \n",
        "  training_data = []\n",
        "  # track balance \n",
        "  balance = {}\n",
        "  #relavent directories \n",
        "  sds = [\"/HAM10000_images_part_1/\", \"/HAM10000_images_part_2/\"]\n",
        "  root = \"/content/drive/MyDrive/HAM10000\"\n",
        "\n",
        "  def __init__(self):\n",
        "    #assign labels\n",
        "    self.make_labels()\n",
        "    #make the map\n",
        "    self.make_image_map()\n",
        "    print(self.labels, self.img_map)\n",
        "  \"\"\" Assign numbers to the diagnosis types\"\"\"\n",
        "  def make_labels(self):\n",
        "    i = 0 \n",
        "    for d in self.mdata[\"dx\"].unique():\n",
        "      self.labels[d] = i \n",
        "      i += 1\n",
        "  \"\"\" Assign to each image the corresponding label \"\"\"\n",
        "  def make_image_map(self):\n",
        "    for im, dx in zip(list(self.mdata[\"image_id\"]), list(self.mdata[\"dx\"])):\n",
        "      self.img_map[im] = self.labels[dx]\n",
        "\n",
        "  def make_training_data(self):\n",
        "    for sd in self.sds:\n",
        "      for f in tqdm(os.listdir(self.root+sd)):\n",
        "        # extract the image id from the file path\n",
        "        id = f.split(\".\")[0].strip(\" \").split(\" \")[0]\n",
        "        if self.img_map[id] not in self.balance:\n",
        "          self.balance[self.img_map[id]] = 0\n",
        "        self.balance[self.img_map[id]] += 1\n",
        "    print(self.balance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA5_shQuOK2J",
        "outputId": "f49a033a-a2a6-4b5a-85bc-f8407eb314d1"
      },
      "outputs": [],
      "source": [
        "dch = DermClassHelper()\n",
        "dch.make_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "CV8qDQUoSINB"
      },
      "outputs": [],
      "source": [
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "YawjtHG4IU__"
      },
      "outputs": [],
      "source": [
        "#write a different data loader class \n",
        "from torch.utils.data import DataLoader\n",
        "class DermClass():\n",
        "  def __init__(self, helper, csv_file, root_dir, sds, transform1=None):\n",
        "    self.derm_frame = pd.read_csv(csv_file) \n",
        "    self.root_dir = root_dir\n",
        "    self.sds = sds \n",
        "    self.transform1 = transform1\n",
        "    #pass in derm class helper here\n",
        "    self.helper = helper\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.derm_frame)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #1 is the image file col \n",
        "    filename = self.derm_frame.iloc[index, 1]\n",
        "    img_path = None\n",
        "    #find the image path\n",
        "    # print(str(self.root_dir+self.sds[0]+filename+\".jpg\"))\n",
        "    if os.path.exists(str(self.root_dir+self.sds[0]+filename+\".jpg\")):\n",
        "      img_path = str(self.root_dir+self.sds[0]+filename+\".jpg\")\n",
        "    elif os.path.exists(str(self.root_dir+self.sds[1]+filename+\".jpg\")):\n",
        "      img_path = str(self.root_dir+self.sds[1]+filename+\".jpg\")\n",
        "    #get the image using PIL \n",
        "    img = Image.open(img_path)\n",
        "    # y_label = torch.tensor(np.eye(len(self.helper.labels))[self.helper.img_map[filename]]) #this is good for adam optim \n",
        "    y_label = torch.tensor(int(self.helper.img_map[filename]))\n",
        "\n",
        "    if self.transform1: \n",
        "      image = self.transform1(img)\n",
        "    return (image, y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "IL5rwW6bQBoK"
      },
      "outputs": [],
      "source": [
        "#hyperparams\n",
        "in_channel = 3\n",
        "num_classes = 7\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "PbGuFgGFalaB"
      },
      "outputs": [],
      "source": [
        "dataset = DermClass(helper=dch, csv_file=\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\", root_dir=\"/content/drive/MyDrive/HAM10000\", sds=[\"/HAM10000_images_part_1/\", \"/HAM10000_images_part_2/\"], transform1=preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "43Q5_nAhPLEN"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = torch.utils.data.random_split(dataset, [int(len(dataset)*.75), int(len(dataset)*.25)+1])\n",
        "\n",
        "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "rFS6MMCw0f8v"
      },
      "outputs": [],
      "source": [
        "# dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "292640b93cd84375a20356b064fdaa43",
            "1eff39a50121422db7d4bfca7e2264ca",
            "683261b9378a4b5386d7d602ad3c93a3",
            "4aa1ecdae8d946efaba2b1707de7cbbf",
            "e33e5f0e4e9f490bb45dd20e3aa29d67",
            "8d95b911fa394b21960c093151020792",
            "262b931702494f8287455e0f96705be8",
            "c8a76267adbb47fd82582c43e1fe00d0",
            "6377a5c449954f89a622f1a45d2c6bcb",
            "b051ec87309b4360a7527dc912bc594e",
            "e60734e8856546108ce2a626a20f63d1"
          ]
        },
        "id": "APxZ_SAbBWdM",
        "outputId": "611d332f-b5df-480e-862d-be78beebc6dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "292640b93cd84375a20356b064fdaa43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#import pretrained \n",
        "import torch\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18')\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVANahfrN5-S",
        "outputId": "09c8554b-1bac-4248-f389-4119a5eab700"
      },
      "outputs": [],
      "source": [
        "#fine tuning - set all of the model gradients to false\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "#change the model architecture a bit\n",
        "model\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
        "                         nn.ReLU(), \n",
        "                         nn.Dropout(p=.5), \n",
        "                         nn.Linear(100,7))\n",
        "\n",
        " \n",
        "#change mode and put on device\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "#example of how to add layers, where net_add is basically the new network that we are interested in: https://discuss.pytorch.org/t/add-layers-on-pretrained-model/88760\n",
        "# net_add=net()\n",
        "# model = nn.Sequential(resnet50, net_add)\n",
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaM8UZyvo1G6",
        "outputId": "1e707d4b-dfd1-464c-fc56-34e814002b21"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCL73uFl7Okw",
        "outputId": "85ebbb3e-0a31-4ce6-8a2b-2adfecc41107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking accuracy on Test Set\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:33<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 1965 / 2504 with accuracy 78.47\n",
            "for class 0, the accuracy is: 0.782609\n",
            "for class 1, the accuracy is: 0.891252\n",
            "for class 2, the accuracy is: 0.156250\n",
            "for class 3, the accuracy is: 0.513699\n",
            "for class 4, the accuracy is: 0.636364\n",
            "for class 5, the accuracy is: 0.591241\n",
            "for class 6, the accuracy is: 0.284091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check accuracy on training to see how good our model is\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    correct = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
        "    total = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader):\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            for i,j in zip(predictions, y):\n",
        "              if i.item() == j.item():\n",
        "                correct[i.item()] +=1\n",
        "              total[j.item()] += 1\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "          )\n",
        "        #find the accuracies for each class \n",
        "        return correct, total\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# print(\"Checking accuracy on Training Set\")\n",
        "# check_accuracy(train_loader, model)\n",
        "\n",
        "print(\"Checking accuracy on Test Set\")\n",
        "correct, total = check_accuracy(test_loader, model)\n",
        "\n",
        "for k in correct:\n",
        "  print(\"for class %d, the accuracy is: %f\" %(k, correct[k]/total[k]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-VRTz4RCEN",
        "outputId": "a37664f1-d805-43a0-98ed-074e0bd1339e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 216, 1: 1467, 2: 5, 3: 150, 4: 21, 5: 81, 6: 25} {0: 276, 1: 1646, 2: 32, 3: 292, 4: 33, 5: 137, 6: 88}\n"
          ]
        }
      ],
      "source": [
        "print(correct, total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3b_CBaY_sTO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit ('3.7.9')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "6779ff44cf17d229830241c018467467eabd002418a5e46f4b3ef249a8203865"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1eff39a50121422db7d4bfca7e2264ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d95b911fa394b21960c093151020792",
            "placeholder": "​",
            "style": "IPY_MODEL_262b931702494f8287455e0f96705be8",
            "value": "100%"
          }
        },
        "262b931702494f8287455e0f96705be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292640b93cd84375a20356b064fdaa43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eff39a50121422db7d4bfca7e2264ca",
              "IPY_MODEL_683261b9378a4b5386d7d602ad3c93a3",
              "IPY_MODEL_4aa1ecdae8d946efaba2b1707de7cbbf"
            ],
            "layout": "IPY_MODEL_e33e5f0e4e9f490bb45dd20e3aa29d67"
          }
        },
        "4aa1ecdae8d946efaba2b1707de7cbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b051ec87309b4360a7527dc912bc594e",
            "placeholder": "​",
            "style": "IPY_MODEL_e60734e8856546108ce2a626a20f63d1",
            "value": " 230M/230M [00:02&lt;00:00, 99.1MB/s]"
          }
        },
        "6377a5c449954f89a622f1a45d2c6bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683261b9378a4b5386d7d602ad3c93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a76267adbb47fd82582c43e1fe00d0",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6377a5c449954f89a622f1a45d2c6bcb",
            "value": 241627721
          }
        },
        "8d95b911fa394b21960c093151020792": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b051ec87309b4360a7527dc912bc594e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a76267adbb47fd82582c43e1fe00d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33e5f0e4e9f490bb45dd20e3aa29d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60734e8856546108ce2a626a20f63d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
