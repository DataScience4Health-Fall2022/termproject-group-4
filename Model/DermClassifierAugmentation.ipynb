{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8q4ez2aLHF1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSP_bk2GJFjw",
        "outputId": "a439b4a7-2a71-410f-bd76-c732a74b972a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcNJ6m5M2mJ",
        "outputId": "497dddc9-4516-4e57-e369-9561df26d278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HAM10000_images_augmented\t HAM10000_metadata.csv\n",
            "HAM10000_images_part_1\t\t HAM10000_segmentations_lesion_tschandl\n",
            "HAM10000_images_part_2\t\t training_data.csv\n",
            "HAM10000_metadata_augmented.csv  training_data.npy\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/HAM10000\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WaP4GWyyONbA",
        "outputId": "54104db8-5e10-4381-adf4-3db76126d917"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ISIC_0026769'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get metadata\n",
        "mdata = pd.read_csv(\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\")\n",
        "mdata\n",
        "mdata.iloc[2, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pnPQuec9M9BM"
      },
      "outputs": [],
      "source": [
        "#transform the function according to the pytorch docs\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "img_size = 224\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    # transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# preprocess2 = preprocess = transforms.Compose([\n",
        "    \n",
        "# ])\n",
        "# input_tensor = preprocess(input_image)\n",
        "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JzL3-QzYNDqz"
      },
      "outputs": [],
      "source": [
        "from pyparsing.helpers import identbodychars\n",
        "class DermClassHelper(): \n",
        "  #make images 50 x 50 to start \n",
        "  mdata = pd.read_csv(\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\").append(pd.read_csv(\"/content/drive/MyDrive/HAM10000/HAM10000_metadata_augmented.csv\"))\n",
        "  IMG_SIZE = 224\n",
        "  labels = {}\n",
        "  img_map = {}\n",
        "  #training data \n",
        "  training_data = []\n",
        "  # track balance \n",
        "  balance = {}\n",
        "  #relavent directories \n",
        "  sds = [\"/HAM10000_images_part_1/\", \"/HAM10000_images_part_2/\", \"/HAM10000_images_augmented/\"]\n",
        "  root = \"/content/drive/MyDrive/HAM10000\"\n",
        "\n",
        "  def __init__(self):\n",
        "    #assign labels\n",
        "    self.make_labels()\n",
        "    #make the map\n",
        "    self.make_image_map()\n",
        "    print(self.labels, self.img_map)\n",
        "  \"\"\" Assign numbers to the diagnosis types\"\"\"\n",
        "  def make_labels(self):\n",
        "    i = 0 \n",
        "    for d in self.mdata[\"dx\"].unique():\n",
        "      self.labels[d] = i \n",
        "      i += 1\n",
        "  \"\"\" Assign to each image the corresponding label \"\"\"\n",
        "  def make_image_map(self):\n",
        "    for im, dx in zip(list(self.mdata[\"image_id\"]), list(self.mdata[\"dx\"])):\n",
        "      self.img_map[im] = self.labels[dx]\n",
        "\n",
        "  def make_training_data(self):\n",
        "    for sd in self.sds:\n",
        "      for f in tqdm(os.listdir(self.root+sd)):\n",
        "        # extract the image id from the file path\n",
        "        id = f.split(\".\")[0].strip(\" \").split(\" \")[0]\n",
        "        if self.img_map[id] not in self.balance:\n",
        "          self.balance[self.img_map[id]] = 0\n",
        "        self.balance[self.img_map[id]] += 1\n",
        "    print(self.balance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA5_shQuOK2J",
        "outputId": "4e56868b-1df5-4175-c698-450d91b631c5"
      },
      "outputs": [],
      "source": [
        "dch = DermClassHelper()\n",
        "dch.make_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CV8qDQUoSINB"
      },
      "outputs": [],
      "source": [
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YawjtHG4IU__"
      },
      "outputs": [],
      "source": [
        "#write a different data loader class \n",
        "from torch.utils.data import DataLoader\n",
        "class DermClass():\n",
        "  def __init__(self, helper, csv_file, root_dir, sds, transform1=None):\n",
        "    self.derm_frame = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.sds = sds \n",
        "    self.transform1 = transform1\n",
        "    #pass in derm class helper here\n",
        "    self.helper = helper\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.derm_frame)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #1 is the image file col \n",
        "    filename = self.derm_frame.iloc[index, 1]\n",
        "    img_path = None\n",
        "    #find the image path  \n",
        "    if os.path.exists(str(self.root_dir+self.sds[0]+filename+\".jpg\")):\n",
        "      img_path = str(self.root_dir+self.sds[0]+filename+\".jpg\")\n",
        "    elif os.path.exists(str(self.root_dir+self.sds[1]+filename+\".jpg\")):\n",
        "      img_path = str(self.root_dir+self.sds[1]+filename+\".jpg\")\n",
        "\n",
        "    #get the image using PIL \n",
        "    img = Image.open(img_path)\n",
        "    # y_label = torch.tensor(np.eye(len(self.helper.labels))[self.helper.img_map[filename]]) #this is good for adam optim \n",
        "    y_label = torch.tensor(int(self.helper.img_map[filename]))\n",
        "\n",
        "    if self.transform1: \n",
        "      image = self.transform1(img)\n",
        "    return (image, y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "IlWJIssSuzid"
      },
      "outputs": [],
      "source": [
        "class AugmentedDermClass():\n",
        "  def __init__(self, helper, csv_file, root_dir, sd, transform1=None):\n",
        "    self.derm_frame = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.sd = sd\n",
        "    self.transform1 = transform1\n",
        "    #pass in derm class helper here\n",
        "    self.helper = helper\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.derm_frame)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #1 is the image file col \n",
        "    filename = self.derm_frame.iloc[index, 1]\n",
        "    # dataset = self.derm_frame.iloc[index, 7]\n",
        "    img_path = None\n",
        "    #find the image path  \n",
        "    if os.path.exists(str(self.root_dir+self.sd+filename+\".jpg\")):\n",
        "      img_path = str(self.root_dir+self.sd+filename+\".jpg\")\n",
        "\n",
        "    #get the image using PIL \n",
        "    img = Image.open(img_path)\n",
        "    # y_label = torch.tensor(np.eye(len(self.helper.labels))[self.helper.img_map[filename]]) #this is good for adam optim \n",
        "    y_label = torch.tensor(int(self.helper.img_map[filename]))\n",
        "\n",
        "    if self.transform1: \n",
        "      image = self.transform1(img)\n",
        "    return (image, y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MJLH9J_aUFU_"
      },
      "outputs": [],
      "source": [
        "# g = DermClass(helper=dch, csv_files=[\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\", \"/content/drive/MyDrive/HAM10000/HAM10000_metadata_augmented.csv\"], root_dir=\"/content/drive/MyDrive/HAM10000\", sds=[\"/HAM10000_images_part_1/\", \"/HAM10000_images_part_2/\", \"/HAM10000_images_augmented/\"], transform1=preprocess)\n",
        "# g.__getitem__(11000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "IL5rwW6bQBoK"
      },
      "outputs": [],
      "source": [
        "#hyperparams\n",
        "in_channel = 3\n",
        "num_classes = 7\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "PbGuFgGFalaB"
      },
      "outputs": [],
      "source": [
        "dataset = DermClass(helper=dch, csv_file=\"/content/drive/MyDrive/HAM10000/HAM10000_metadata.csv\", root_dir=\"/content/drive/MyDrive/HAM10000\", sds=[\"/HAM10000_images_part_1/\", \"/HAM10000_images_part_2/\"], transform1=preprocess)\n",
        "\n",
        "augmented_dataset = AugmentedDermClass(helper=dch, csv_file=\"/content/drive/MyDrive/HAM10000/HAM10000_metadata_augmented.csv\", root_dir=\"/content/drive/MyDrive/HAM10000\", sd= \"/HAM10000_images_augmented/\", transform1=preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "5xx694ndvwcD"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = torch.utils.data.random_split(dataset, [int(len(dataset)*.75), int(len(dataset)*.25)+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "43Q5_nAhPLEN"
      },
      "outputs": [],
      "source": [
        "#here, we need to find a way to add augmented images to training and exclude them from testing \n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [int(len(dataset)*.75), int(len(dataset)*.25)+1])\n",
        "\n",
        "#add the augmented data to the train set\n",
        "train_set = torch.utils.data.ConcatDataset([train_set, augmented_dataset])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkKDUV25T7O4",
        "outputId": "0b6178b7-4fd0-4618-8aa9-2e4cbae60a0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "rFS6MMCw0f8v"
      },
      "outputs": [],
      "source": [
        "# dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APxZ_SAbBWdM",
        "outputId": "fd61bec8-2534-4a91-f15e-523afd42cc76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "#import pretrained \n",
        "import torch\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18',  pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVANahfrN5-S",
        "outputId": "9f167479-96aa-404c-eb23-7f8106ae4d2e"
      },
      "outputs": [],
      "source": [
        "#fine tuning - set all of the model gradients to false\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "#change the model architecture a bit\n",
        "model\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
        "                         nn.ReLU(), \n",
        "                         nn.Dropout(p=.5), \n",
        "                         nn.Linear(100,7))\n",
        "\n",
        " \n",
        "#change mode and put on device\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "#example of how to add layers, where net_add is basically the new network that we are interested in: https://discuss.pytorch.org/t/add-layers-on-pretrained-model/88760\n",
        "# net_add=net()\n",
        "# model = nn.Sequential(resnet50, net_add)\n",
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaM8UZyvo1G6",
        "outputId": "42e6984d-48e1-4a4b-c83e-8463d4984113"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCL73uFl7Okw",
        "outputId": "bbe2f0b0-2409-41de-daad-7a7efbfac590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking accuracy on Test Set\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:32<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 2002 / 2504 with accuracy 79.95\n",
            "for class 0, the accuracy is: 0.547244\n",
            "for class 1, the accuracy is: 0.965290\n",
            "for class 2, the accuracy is: 0.121212\n",
            "for class 3, the accuracy is: 0.370107\n",
            "for class 4, the accuracy is: 0.485714\n",
            "for class 5, the accuracy is: 0.578231\n",
            "for class 6, the accuracy is: 0.481928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check accuracy on training to see how good our model is\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    correct = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
        "    total = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0}\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader):\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            for i,j in zip(predictions, y):\n",
        "              if i.item() == j.item():\n",
        "                correct[i.item()] +=1\n",
        "              total[j.item()] += 1\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "          )\n",
        "        #find the accuracies for each class \n",
        "        return correct, total\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# print(\"Checking accuracy on Training Set\")\n",
        "# check_accuracy(train_loader, model)\n",
        "\n",
        "print(\"Checking accuracy on Test Set\")\n",
        "correct, total = check_accuracy(test_loader, model)\n",
        "\n",
        "for k in correct:\n",
        "  print(\"for class %d, the accuracy is: %f\" %(k, correct[k]/total[k]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-VRTz4RCEN",
        "outputId": "a388fc75-c527-489c-b8d8-4bb43354526a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 139, 1: 1613, 2: 4, 3: 104, 4: 17, 5: 85, 6: 40} {0: 254, 1: 1671, 2: 33, 3: 281, 4: 35, 5: 147, 6: 83}\n"
          ]
        }
      ],
      "source": [
        "print(correct, total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3b_CBaY_sTO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
